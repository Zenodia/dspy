{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c8c848d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading data: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 505k/505k [00:01<00:00, 254kB/s]\n",
      "Downloading data: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 353k/353k [00:00<00:00, 520kB/s]\n",
      "Generating train split: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1744/1744 [00:00<00:00, 175076.38 examples/s]\n",
      "Generating test split: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1187/1187 [00:00<00:00, 208923.16 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350 350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from dspy.datasets import MATH\n",
    "\n",
    "dataset = MATH(subset='algebra')\n",
    "print(len(dataset.train), len(dataset.dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2a01563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method MATH.metric of <dspy.datasets.math.MATH object at 0x7f05d6dc6f80>>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d561f0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import dspy\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "base_url = 'https://integrate.api.nvidia.com/v1'\n",
    "model = \"meta/llama-3.3-70b-instruct\"\n",
    "\n",
    "llama33_70b = dspy.LM(f'openai/{model}', api_key=os.environ[\"NVIDIA_API_KEY\"], api_base=base_url)\n",
    "\n",
    "mixtral8x22b = dspy.LM('openai/nvdev/mistralai/mixtral-8x22b-instruct-v0.1', api_key=os.environ[\"NV_DEV_API_KEY\"], api_base=base_url, temperature=0.7)\n",
    "\n",
    "dspy.configure(lm=mixtral8x22b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867a9eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## read in nvbug example excel sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fdef7c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>startphrase</th>\n",
       "      <th>ending0</th>\n",
       "      <th>ending1</th>\n",
       "      <th>ending2</th>\n",
       "      <th>ending3</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Which factor will most likely cause a person to develop a fever?</td>\n",
       "      <td>a leg muscle relaxing after exercise</td>\n",
       "      <td>a bacterial population in the bloodstream</td>\n",
       "      <td>several viral particles on the skin</td>\n",
       "      <td>carbohydrates being digested in the stomach</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Lichens are symbiotic organisms made of green algae and fungi. Wha...</td>\n",
       "      <td>carbon dioxide</td>\n",
       "      <td>food</td>\n",
       "      <td>protection</td>\n",
       "      <td>water</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>When a switch is used in an electrical circuit, the switch can</td>\n",
       "      <td>cause the charge to build.</td>\n",
       "      <td>increase and decrease the voltage.</td>\n",
       "      <td>cause the current to change direction.</td>\n",
       "      <td>stop and start the flow of current.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Which of the following is an example of an assistive device?</td>\n",
       "      <td>contact lens</td>\n",
       "      <td>motorcycle</td>\n",
       "      <td>raincoat</td>\n",
       "      <td>coffee pot</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Rocks are classified as igneous, metamorphic, or sedimentary accor...</td>\n",
       "      <td>their color</td>\n",
       "      <td>their shape</td>\n",
       "      <td>how they formed</td>\n",
       "      <td>the minerals they contain</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  \\\n",
       "0           0   \n",
       "1           1   \n",
       "2           2   \n",
       "3           3   \n",
       "4           4   \n",
       "\n",
       "                                                             startphrase  \\\n",
       "0      Which factor will most likely cause a person to develop a fever?    \n",
       "1  Lichens are symbiotic organisms made of green algae and fungi. Wha...   \n",
       "2        When a switch is used in an electrical circuit, the switch can    \n",
       "3          Which of the following is an example of an assistive device?    \n",
       "4  Rocks are classified as igneous, metamorphic, or sedimentary accor...   \n",
       "\n",
       "                                  ending0  \\\n",
       "0   a leg muscle relaxing after exercise    \n",
       "1                         carbon dioxide    \n",
       "2             cause the charge to build.    \n",
       "3                           contact lens    \n",
       "4                            their color    \n",
       "\n",
       "                                       ending1  \\\n",
       "0   a bacterial population in the bloodstream    \n",
       "1                                        food    \n",
       "2          increase and decrease the voltage.    \n",
       "3                                  motorcycle    \n",
       "4                                 their shape    \n",
       "\n",
       "                                    ending2  \\\n",
       "0      several viral particles on the skin    \n",
       "1                               protection    \n",
       "2   cause the current to change direction.    \n",
       "3                                 raincoat    \n",
       "4                          how they formed    \n",
       "\n",
       "                                        ending3  label  \n",
       "0   carbohydrates being digested in the stomach      1  \n",
       "1                                         water      1  \n",
       "2           stop and start the flow of current.      3  \n",
       "3                                    coffee pot      0  \n",
       "4                     the minerals they contain      2  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#xls = pd.ExcelFile('/workspace/nvdata/Eval data set.xlsx')\n",
    "#df1 = pd.read_excel(xls, 'Single Bug Details')\n",
    "train=pd.read_csv('/workspace/nvdata/train.csv')\n",
    "train.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77247a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>API Response</th>\n",
       "      <th>Response Time (sec)</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what is the reason for delay in this bug fix f...</td>\n",
       "      <td>{'Category': 'detailed', 'count': 0, 'list': [...</td>\n",
       "      <td>7.143266</td>\n",
       "      <td>Accurate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Can you suggest if a bug 4504063 can be closed,</td>\n",
       "      <td>{'Category': 'detailed', 'count': 0, 'list': [...</td>\n",
       "      <td>3.785950</td>\n",
       "      <td>Accurate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>list all delays in responses between comments ...</td>\n",
       "      <td>{'Category': 'detailed', 'count': 0, 'list': [...</td>\n",
       "      <td>5.738200</td>\n",
       "      <td>Accurate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Who was the last person to comment on Bug 4323...</td>\n",
       "      <td>{'Category': 'detailed', 'count': 0, 'list': [...</td>\n",
       "      <td>2.580094</td>\n",
       "      <td>Accurate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What changes were made in Bug 4323093 in the l...</td>\n",
       "      <td>{'Category': 'detailed', 'count': 0, 'list': [...</td>\n",
       "      <td>3.815290</td>\n",
       "      <td>Accurate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Can Bug 4323093 be marked as resolved?,</td>\n",
       "      <td>{'Category': 'detailed', 'count': 0, 'list': [...</td>\n",
       "      <td>3.152200</td>\n",
       "      <td>Accurate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Who is the current QA Engineer for Bug 4323093?,</td>\n",
       "      <td>{'Category': 'detailed', 'count': 0, 'list': [...</td>\n",
       "      <td>2.482323</td>\n",
       "      <td>Accurate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>What is the current status of Bug 4323093?,</td>\n",
       "      <td>{'Category': 'detailed', 'count': 0, 'list': [...</td>\n",
       "      <td>3.656847</td>\n",
       "      <td>Accurate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Which module is Bug 4323093 associated with?,</td>\n",
       "      <td>{'Category': 'detailed', 'count': 0, 'list': [...</td>\n",
       "      <td>2.447568</td>\n",
       "      <td>Accurate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>What is the severity level of Bug 4323093?,</td>\n",
       "      <td>{'Category': 'detailed', 'count': 0, 'list': [...</td>\n",
       "      <td>2.429880</td>\n",
       "      <td>Accurate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Who filed Bug 4323093?,</td>\n",
       "      <td>{'Category': 'detailed', 'count': 0, 'list': [...</td>\n",
       "      <td>2.519444</td>\n",
       "      <td>Accurate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Is there a workaround for Bug 4323093?,</td>\n",
       "      <td>{'Category': 'detailed', 'count': 0, 'list': [...</td>\n",
       "      <td>4.246862</td>\n",
       "      <td>Accurate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>What is the current priority of Bug 4323093?,</td>\n",
       "      <td>{'Category': 'detailed', 'count': 0, 'list': [...</td>\n",
       "      <td>2.722087</td>\n",
       "      <td>Accurate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>What division does Bug 4323093 belong to?,</td>\n",
       "      <td>{'Category': 'detailed', 'count': 0, 'list': [...</td>\n",
       "      <td>2.521323</td>\n",
       "      <td>Accurate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>What categories are associated with Bug 4323093?,</td>\n",
       "      <td>{'Category': 'detailed', 'count': 0, 'list': [...</td>\n",
       "      <td>2.656065</td>\n",
       "      <td>Accurate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>What is the type of Bug 4323093?,</td>\n",
       "      <td>{'Category': 'detailed', 'count': 0, 'list': [...</td>\n",
       "      <td>2.145559</td>\n",
       "      <td>Accurate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Who is the engineer assigned to Bug 4323093?,</td>\n",
       "      <td>{'Category': 'detailed', 'count': 0, 'list': [...</td>\n",
       "      <td>2.354089</td>\n",
       "      <td>Accurate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Query  \\\n",
       "0   what is the reason for delay in this bug fix f...   \n",
       "4     Can you suggest if a bug 4504063 can be closed,   \n",
       "7   list all delays in responses between comments ...   \n",
       "8   Who was the last person to comment on Bug 4323...   \n",
       "9   What changes were made in Bug 4323093 in the l...   \n",
       "10            Can Bug 4323093 be marked as resolved?,   \n",
       "11   Who is the current QA Engineer for Bug 4323093?,   \n",
       "12        What is the current status of Bug 4323093?,   \n",
       "13      Which module is Bug 4323093 associated with?,   \n",
       "15        What is the severity level of Bug 4323093?,   \n",
       "17                            Who filed Bug 4323093?,   \n",
       "19            Is there a workaround for Bug 4323093?,   \n",
       "20      What is the current priority of Bug 4323093?,   \n",
       "22         What division does Bug 4323093 belong to?,   \n",
       "24  What categories are associated with Bug 4323093?,   \n",
       "25                  What is the type of Bug 4323093?,   \n",
       "28      Who is the engineer assigned to Bug 4323093?,   \n",
       "\n",
       "                                         API Response  Response Time (sec)  \\\n",
       "0   {'Category': 'detailed', 'count': 0, 'list': [...             7.143266   \n",
       "4   {'Category': 'detailed', 'count': 0, 'list': [...             3.785950   \n",
       "7   {'Category': 'detailed', 'count': 0, 'list': [...             5.738200   \n",
       "8   {'Category': 'detailed', 'count': 0, 'list': [...             2.580094   \n",
       "9   {'Category': 'detailed', 'count': 0, 'list': [...             3.815290   \n",
       "10  {'Category': 'detailed', 'count': 0, 'list': [...             3.152200   \n",
       "11  {'Category': 'detailed', 'count': 0, 'list': [...             2.482323   \n",
       "12  {'Category': 'detailed', 'count': 0, 'list': [...             3.656847   \n",
       "13  {'Category': 'detailed', 'count': 0, 'list': [...             2.447568   \n",
       "15  {'Category': 'detailed', 'count': 0, 'list': [...             2.429880   \n",
       "17  {'Category': 'detailed', 'count': 0, 'list': [...             2.519444   \n",
       "19  {'Category': 'detailed', 'count': 0, 'list': [...             4.246862   \n",
       "20  {'Category': 'detailed', 'count': 0, 'list': [...             2.722087   \n",
       "22  {'Category': 'detailed', 'count': 0, 'list': [...             2.521323   \n",
       "24  {'Category': 'detailed', 'count': 0, 'list': [...             2.656065   \n",
       "25  {'Category': 'detailed', 'count': 0, 'list': [...             2.145559   \n",
       "28  {'Category': 'detailed', 'count': 0, 'list': [...             2.354089   \n",
       "\n",
       "   Unnamed: 3  \n",
       "0    Accurate  \n",
       "4    Accurate  \n",
       "7    Accurate  \n",
       "8    Accurate  \n",
       "9    Accurate  \n",
       "10   Accurate  \n",
       "11   Accurate  \n",
       "12   Accurate  \n",
       "13   Accurate  \n",
       "15   Accurate  \n",
       "17   Accurate  \n",
       "19   Accurate  \n",
       "20   Accurate  \n",
       "22   Accurate  \n",
       "24   Accurate  \n",
       "25   Accurate  \n",
       "28   Accurate  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## filter to get only the accurate examples\n",
    "correct_col=list(df1.columns)[-1]\n",
    "df=df1[df1[correct_col]==\"Accurate\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d0bbab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba610022",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 566M/566M [00:21<00:00, 26.1MB/s]\n",
      "Downloading data: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 47.5M/47.5M [00:02<00:00, 19.8MB/s]\n",
      "Downloading data: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 46.2M/46.2M [00:02<00:00, 19.5MB/s]\n",
      "Generating train split: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 90447/90447 [00:20<00:00, 4516.04 examples/s]\n",
      "Generating validation split: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7405/7405 [00:01<00:00, 4344.16 examples/s]\n",
      "Generating test split: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7405/7405 [00:01<00:00, 4764.60 examples/s]\n"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "from dspy.datasets import HotPotQA\n",
    "\n",
    "## can replace with anything that return a list of texts, e.g retrieved from RAG\n",
    "def search_wikipedia(query: str) -> list[str]:\n",
    "    results = dspy.ColBERTv2(url='http://20.102.90.50:2017/wiki17_abstracts')(query, k=3)\n",
    "    return [x['text'] for x in results]\n",
    "\n",
    "trainset = [x.with_inputs('question') for x in HotPotQA(train_seed=2024, train_size=500).train]\n",
    "react = dspy.ReAct(\"question -> answer\", tools=[search_wikipedia])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4ef14461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Example({'question': 'Are Smyrnium and Nymania both types of plant?', 'answer': 'yes'}) (input_keys={'question'})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec98986a",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_wikipedia(\"David Gregory was born in 1625.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca71a86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from dspy.datasets import DataLoader\n",
    "\n",
    "kwargs = dict(fields=(\"claim\", \"supporting_facts\", \"hpqa_id\", \"num_hops\"), input_keys=(\"claim\",))\n",
    "hover = DataLoader().from_huggingface(dataset_name=\"hover-nlp/hover\", split=\"train\", trust_remote_code=True, **kwargs)\n",
    "\n",
    "hpqa_ids = set()\n",
    "hover = [\n",
    "    dspy.Example(declare=x.claim, titles=list(set([y[\"key\"] for y in x.supporting_facts]))).with_inputs(\"declare\")\n",
    "    for x in hover\n",
    "    if x[\"num_hops\"] == 3 and x[\"hpqa_id\"] not in hpqa_ids and not hpqa_ids.add(x[\"hpqa_id\"])\n",
    "]\n",
    "\n",
    "random.Random(0).shuffle(hover)\n",
    "trainset, devset, testset = hover[:20], hover[20:40], hover[40:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "711b515c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7bfa924e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd5b409",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018be0cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d9c751f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Example({'declare': 'This director is known for his work on Miss Potter. The Academy of Motion Picture Arts and Sciences presents the award in which he was nominated for his work in \"Babe\".', 'titles': ['Miss Potter', 'Academy Award for Best Director', 'Chris Noonan']}) (input_keys={'declare'})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = trainset[0]\n",
    "\n",
    "example"
   ]
  },
  {
   "cell_type": "raw",
   "id": "494d7ae5",
   "metadata": {},
   "source": [
    "DOCS = {}\n",
    "\n",
    "def search(query: str, k: int) -> list[str]:\n",
    "    results = dspy.ColBERTv2(url='http://20.102.90.50:2017/wiki17_abstracts')(query, k=k)\n",
    "    results = [x['text'] for x in results]\n",
    "\n",
    "    for result in results:\n",
    "        title, text = result.split(\" | \", 1)\n",
    "        DOCS[title] = text\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "515edf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_wikipedia(query: str) -> list[str]:\n",
    "    \"\"\"Returns top-5 results and then the titles of the top-5 to top-30 results.\"\"\"\n",
    "\n",
    "    topK = search(query, 30)\n",
    "    titles, topK = [f\"`{x.split(' | ')[0]}`\" for x in topK[5:30]], topK[:5]\n",
    "    return topK + [f\"Other retrieved pages have titles: {', '.join(titles)}.\"]\n",
    "\n",
    "def lookup_wikipedia(title: str) -> str:\n",
    "    \"\"\"Returns the text of the Wikipedia page, if it exists.\"\"\"\n",
    "\n",
    "    if title in DOCS:\n",
    "        return DOCS[title]\n",
    "\n",
    "    results = [x for x in search(title, 10) if x.startswith(title + \" | \")]\n",
    "    if not results:\n",
    "        return f\"No Wikipedia page found for title: {title}\"\n",
    "    return results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc1f8b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signagure >>>  StringSignature(declare -> titles\n",
      "    instructions='Find all Wikipedia titles relevant to verifying (or refuting) the declaration.'\n",
      "    declare = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Declare:', 'desc': '${declare}'})\n",
      "    titles = Field(annotation=list[str] required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Titles:', 'desc': '${titles}'})\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "instructions = \"Find all Wikipedia titles relevant to verifying (or refuting) the declaration.\"\n",
    "signature = dspy.Signature(\"declare -> titles: list[str]\", instructions)\n",
    "print(\"signagure >>> \", signature )\n",
    "react = dspy.ReAct(signature, tools=[search_wikipedia, lookup_wikipedia], max_iters=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c1ddb65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['David Gregory (physician)']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "react(declare=\"David Gregory was born in 1625.\").titles[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1cad4eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top5_recall(example, pred, trace=None):\n",
    "    gold_titles = example.titles\n",
    "    print('**pred titles **',[x for x in pred.titles[:5] ])\n",
    "    print(\"'\\n'\")\n",
    "    print('---> gold titles', [x for x in gold_titles])\n",
    "    recall = sum(x in pred.titles[:5] for x in gold_titles) / len(gold_titles)\n",
    "\n",
    "    # If we're \"bootstrapping\" for optimization, return True if and only if the recall is perfect.\n",
    "    if trace is not None:\n",
    "        return recall >= 1.0\n",
    "    \n",
    "    # If we're just doing inference, just measure the recall.\n",
    "    return recall\n",
    "\n",
    "evaluate = dspy.Evaluate(devset=devset, metric=top5_recall, num_threads=16, display_progress=True, display_table=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2634fdb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                     | 0/20 [00:00<?, ?it/s]**pred titles ** []\n",
      "'\n",
      "'\n",
      "---> gold titles ['Ternstroemia', 'Cussonia', 'Seemannaralia gerrardii']\n",
      "Average Metric: 0.00 / 1 (0.0%):   5%|███████                                                                                                                                     | 1/20 [00:30<09:42, 30.63s/it]**pred titles ** []\n",
      "'\n",
      "'\n",
      "---> gold titles ['Chen Xiuke', 'Danyang, Jiangsu', 'Dongfang, Hainan']\n",
      "Average Metric: 0.00 / 2 (0.0%):  10%|██████████████                                                                                                                              | 2/20 [00:32<04:09, 13.85s/it]**pred titles ** [\"Daniel Boone's Trail\", 'Arcadia, Tennessee', 'Green-Jones War', 'National Road']\n",
      "'\n",
      "'\n",
      "---> gold titles ['Arcadia, Tennessee', 'Greene–Jones War', 'Wilderness Road']\n",
      "Average Metric: 0.33 / 3 (11.1%):  15%|████████████████████▊                                                                                                                      | 3/20 [00:34<02:19,  8.22s/it]**pred titles ** []\n",
      "'\n",
      "'\n",
      "---> gold titles ['VIVA Media', 'Viva (UK and Ireland)', 'Gesellschaft mit beschränkter Haftung']\n",
      "Average Metric: 0.33 / 4 (8.3%):  15%|█████████████████████                                                                                                                       | 3/20 [00:34<02:19,  8.22s/it]**pred titles ** ['Me Before You (film)', 'Thea Sharrock', 'The Lost Future', 'The Hunger Games', 'Will Traynor']\n",
      "'\n",
      "'\n",
      "---> gold titles ['The Lost Future', 'Sam Claflin', 'Me Before You (film)']\n",
      "Average Metric: 1.00 / 5 (20.0%):  25%|██████████████████████████████████▊                                                                                                        | 5/20 [00:36<01:03,  4.20s/it]**pred titles ** ['From the Manger to the Cross', 'Denis Villeneuve', 'Those Who Make Revolution Halfway']\n",
      "'\n",
      "'\n",
      "---> gold titles ['From the Manger to the Cross', 'Sidney Olcott', 'Denis Villeneuve']\n",
      "Average Metric: 1.67 / 6 (27.8%):  30%|█████████████████████████████████████████▋                                                                                                 | 6/20 [00:40<00:56,  4.02s/it]**pred titles ** ['Christopher Whitelaw Pine', 'Good Luck! (film)', 'Into the Woods (film)']\n",
      "'\n",
      "'\n",
      "---> gold titles ['Good Luck!', 'Just My Luck (2006 film)', 'Chris Pine']\n",
      "Average Metric: 1.67 / 7 (23.8%):  35%|████████████████████████████████████████████████▋                                                                                          | 7/20 [00:40<00:37,  2.89s/it]**pred titles ** ['Il trovatore', 'Magic Hunter']\n",
      "'\n",
      "'\n",
      "---> gold titles ['Der Freischütz', 'Il trovatore', 'Magic Hunter']\n",
      "Average Metric: 2.33 / 8 (29.2%):  40%|███████████████████████████████████████████████████████▌                                                                                   | 8/20 [00:40<00:25,  2.15s/it]**pred titles ** ['Frank Darabont', 'The Mist (film)', 'The Green Mile (film)', 'The Walking Dead (TV series)']\n",
      "'\n",
      "'\n",
      "---> gold titles ['Frank Darabont', 'The Mist (film)', 'T-Dog (The Walking Dead)']\n",
      "Average Metric: 3.00 / 9 (33.3%):  45%|██████████████████████████████████████████████████████████████▌                                                                            | 9/20 [00:46<00:36,  3.33s/it]**pred titles ** ['Dawn French', 'Gary Barlow']\n",
      "'\n",
      "'\n",
      "---> gold titles ['Nothing to Report', 'Chris Jericho', 'Gary Barlow']\n",
      "Average Metric: 3.33 / 10 (33.3%):  50%|████████████████████████████████████████████████████████████████████▌                                                                    | 10/20 [00:47<00:25,  2.51s/it]**pred titles ** ['Yui (singer)']\n",
      "'\n",
      "'\n",
      "---> gold titles ['Jonathan Davis', 'Singing Bird', 'Koshi Inaba']\n",
      "Average Metric: 3.33 / 11 (30.3%):  55%|███████████████████████████████████████████████████████████████████████████▎                                                             | 11/20 [00:51<00:27,  3.00s/it]**pred titles ** ['Actors born in 1955', 'Movies that inspired Blackmail (2005 film)', 'Golden Globe Award nominees']\n",
      "'\n",
      "'\n",
      "---> gold titles ['Ransom (1996 film)', 'Gary Sinise', 'Blackmail (2005 film)']\n",
      "Average Metric: 0.00 / 0 (0%):   5%|███████                                                                                                                                      | 1/20 [02:05<39:38, 125.17s/it]\n",
      "Average Metric: 0.00 / 0 (0%):   5%|███████                                                                                                                                       | 1/20 [01:25<27:11, 85.88s/it]\n",
      "**pred titles ** ['Guðný Halldórsdóttir', 'Timothy Leary']\n",
      "'\n",
      "'\n",
      "---> gold titles ['Halldór Laxness', 'Timothy Leary', 'Guðný Halldórsdóttir']\n",
      "Average Metric: 4.00 / 13 (30.8%):  65%|█████████████████████████████████████████████████████████████████████████████████████████                                                | 13/20 [01:14<00:57,  8.15s/it]**pred titles ** []\n",
      "'\n",
      "'\n",
      "---> gold titles ['Chas Chandler (comics)', 'Hellblazer Special: Bad Blood', 'John Constantine']\n",
      "Average Metric: 4.00 / 14 (28.6%):  70%|███████████████████████████████████████████████████████████████████████████████████████████████▉                                         | 14/20 [01:15<00:36,  6.06s/it]**pred titles ** []\n",
      "'\n",
      "'\n",
      "---> gold titles ['Edward H. Griffith', 'Edward Burns', 'Young and Willing']\n",
      "Average Metric: 4.00 / 15 (26.7%):  75%|██████████████████████████████████████████████████████████████████████████████████████████████████████▊                                  | 15/20 [01:43<01:03, 12.73s/it]**pred titles ** []\n",
      "'\n",
      "'\n",
      "---> gold titles ['Billy Anderson (producer)', 'Red House Painters', 'Daughtry (band)']\n",
      "Average Metric: 4.00 / 16 (25.0%):  80%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                           | 16/20 [01:50<00:43, 10.85s/it]**pred titles ** ['Isaiah Mustafa', 'Chuck Versus the A-Team', 'Old Spice']\n",
      "'\n",
      "'\n",
      "---> gold titles ['Chuck Versus the A-Team', 'Isaiah Mustafa', 'Make a Smellmitment']\n",
      "Average Metric: 4.67 / 17 (27.5%):  80%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                           | 16/20 [01:50<00:43, 10.85s/it]**pred titles ** ['400 Boys', 'Actor who played in 400 Boys', 'Marilyn Monroe film based on Northern Lights', 'Actor who played Marilyn Monroe in film based on Northern Lights']\n",
      "'\n",
      "'\n",
      "---> gold titles ['400 Boys', 'Charlie Rowe', 'The Golden Compass (film)']\n",
      "Average Metric: 5.00 / 18 (27.8%):  90%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎             | 18/20 [02:06<00:19,  9.58s/it]**pred titles ** ['Roger Cicero', 'cEvin Key', 'Rx (band)']\n",
      "'\n",
      "'\n",
      "---> gold titles ['Nivek Ogre', 'Rx (band)', 'Frank Sinatra']\n",
      "Average Metric: 5.33 / 19 (28.1%):  95%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏      | 19/20 [02:06<00:07,  7.33s/it]**pred titles ** ['Batman: Mask of the Phantasm', 'Avengers Assemble (TV series)', 'List of Batman animated television series directors', 'List of Avengers Assemble episodes']\n",
      "'\n",
      "'\n",
      "---> gold titles ['Eric Radomski', 'Batman: Mask of the Phantasm', 'Avengers Assemble (TV series)']\n",
      "Average Metric: 6.00 / 20 (30.0%): 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [02:10<00:00,  6.54s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/08 14:54:26 INFO dspy.evaluate.evaluate: Average Metric: 6.0 / 20 (30.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>declare</th>\n",
       "      <th>example_titles</th>\n",
       "      <th>trajectory</th>\n",
       "      <th>reasoning</th>\n",
       "      <th>pred_titles</th>\n",
       "      <th>top5_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jonathan Howsmon Davis lives closer to Canada than this Japanese s...</td>\n",
       "      <td>[Jonathan Davis, Singing Bird, Koshi Inaba]</td>\n",
       "      <td>{'thought_0': \"The first task is to identify the Japanese singer w...</td>\n",
       "      <td>The task was to find relevant Wikipedia titles to verify the decla...</td>\n",
       "      <td>[Yui (singer)]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>An actor born in 1955 that acted in the movie that was the inspira...</td>\n",
       "      <td>[Ransom (1996 film), Gary Sinise, Blackmail (2005 film)]</td>\n",
       "      <td>{'thought_0': 'The declaration consists of multiple parts: the bir...</td>\n",
       "      <td>The declaration is composed of three main parts: an actor born in ...</td>\n",
       "      <td>[Actors born in 1955, Movies that inspired Blackmail (2005 film), ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The star of Nothing to Report and Gary Barlow have a profession in...</td>\n",
       "      <td>[Nothing to Report, Chris Jericho, Gary Barlow]</td>\n",
       "      <td>{'thought_0': 'To verify this declaration, I need to find the prof...</td>\n",
       "      <td>To verify the declaration, I needed to find the professions of bot...</td>\n",
       "      <td>[Dawn French, Gary Barlow]</td>\n",
       "      <td>✔️ [0.333]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Neither the director of the 1943 film \"Young and Willing\" nor Edwa...</td>\n",
       "      <td>[Edward H. Griffith, Edward Burns, Young and Willing]</td>\n",
       "      <td>{'thought_0': 'I need to verify the nationality of the director of...</td>\n",
       "      <td>I attempted to find the Wikipedia page for the director of the fil...</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The actor, who starred in the thriller 400 Boys, plays Marilyn Mon...</td>\n",
       "      <td>[400 Boys, Charlie Rowe, The Golden Compass (film)]</td>\n",
       "      <td>{'thought_0': 'To verify this declaration, I need to find the acto...</td>\n",
       "      <td>To verify the given declaration, I would need to find the actor wh...</td>\n",
       "      <td>['400 Boys', 'Actor who played in 400 Boys', 'Marilyn Monroe film ...</td>\n",
       "      <td>✔️ [0.333]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 declare  \\\n",
       "0  Jonathan Howsmon Davis lives closer to Canada than this Japanese s...   \n",
       "1  An actor born in 1955 that acted in the movie that was the inspira...   \n",
       "2  The star of Nothing to Report and Gary Barlow have a profession in...   \n",
       "3  Neither the director of the 1943 film \"Young and Willing\" nor Edwa...   \n",
       "4  The actor, who starred in the thriller 400 Boys, plays Marilyn Mon...   \n",
       "\n",
       "                                             example_titles  \\\n",
       "0               [Jonathan Davis, Singing Bird, Koshi Inaba]   \n",
       "1  [Ransom (1996 film), Gary Sinise, Blackmail (2005 film)]   \n",
       "2           [Nothing to Report, Chris Jericho, Gary Barlow]   \n",
       "3     [Edward H. Griffith, Edward Burns, Young and Willing]   \n",
       "4       [400 Boys, Charlie Rowe, The Golden Compass (film)]   \n",
       "\n",
       "                                                              trajectory  \\\n",
       "0  {'thought_0': \"The first task is to identify the Japanese singer w...   \n",
       "1  {'thought_0': 'The declaration consists of multiple parts: the bir...   \n",
       "2  {'thought_0': 'To verify this declaration, I need to find the prof...   \n",
       "3  {'thought_0': 'I need to verify the nationality of the director of...   \n",
       "4  {'thought_0': 'To verify this declaration, I need to find the acto...   \n",
       "\n",
       "                                                               reasoning  \\\n",
       "0  The task was to find relevant Wikipedia titles to verify the decla...   \n",
       "1  The declaration is composed of three main parts: an actor born in ...   \n",
       "2  To verify the declaration, I needed to find the professions of bot...   \n",
       "3  I attempted to find the Wikipedia page for the director of the fil...   \n",
       "4  To verify the given declaration, I would need to find the actor wh...   \n",
       "\n",
       "                                                             pred_titles  \\\n",
       "0                                                         [Yui (singer)]   \n",
       "1  [Actors born in 1955, Movies that inspired Blackmail (2005 film), ...   \n",
       "2                                             [Dawn French, Gary Barlow]   \n",
       "3                                                                     []   \n",
       "4  ['400 Boys', 'Actor who played in 400 Boys', 'Marilyn Monroe film ...   \n",
       "\n",
       "  top5_recall  \n",
       "0              \n",
       "1              \n",
       "2  ✔️ [0.333]  \n",
       "3              \n",
       "4  ✔️ [0.333]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <div style='\n",
       "                    text-align: center;\n",
       "                    font-size: 16px;\n",
       "                    font-weight: bold;\n",
       "                    color: #555;\n",
       "                    margin: 10px 0;'>\n",
       "                    ... 15 more rows not displayed ...\n",
       "                </div>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "30.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def safe_react(declare: str):\n",
    "    try:\n",
    "        return react(declare=declare)\n",
    "    except Exception as e:\n",
    "        return dspy.Prediction(titles=[])\n",
    "\n",
    "evaluate(safe_react)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "753f9c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-01-08T14:54:26.968628]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `declare` (str)\n",
      "2. `trajectory` (str)\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `titles` (list[str])\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## declare ## ]]\n",
      "{declare}\n",
      "\n",
      "[[ ## trajectory ## ]]\n",
      "{trajectory}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## titles ## ]]\n",
      "{titles}        # note: the value you produce must be pareseable according to the following JSON schema: {\"type\": \"array\", \"items\": {\"type\": \"string\"}}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        Find all Wikipedia titles relevant to verifying (or refuting) the declaration.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## declare ## ]]\n",
      "The director of action movie Batman: Mask of the Phantasm, produced Avengers Assemble that premiered on Disney XD on May 26, 2013.\n",
      "\n",
      "[[ ## trajectory ## ]]\n",
      "[[ ## thought_0 ## ]]\n",
      "The declaration suggests that the director of \"Batman: Mask of the Phantasm\" also directed \"Avengers Assemble\". I need to find out who directed both films to verify this claim.\n",
      "\n",
      "[[ ## tool_name_0 ## ]]\n",
      "search_wikipedia\n",
      "\n",
      "[[ ## tool_args_0 ## ]]\n",
      "{\"query\": \"Batman: Mask of the Phantasm director\"}\n",
      "\n",
      "[[ ## observation_0 ## ]]\n",
      "Failed to execute: name 'search' is not defined\n",
      "\n",
      "[[ ## thought_1 ## ]]\n",
      "Apologies for the confusion earlier. I need to find the director of \"Batman: Mask of the Phantasm\" to verify the claim. I will use the search_wikipedia tool to find this information.\n",
      "\n",
      "[[ ## tool_name_1 ## ]]\n",
      "search_wikipedia\n",
      "\n",
      "[[ ## tool_args_1 ## ]]\n",
      "{\"query\": \"Batman: Mask of the Phantasm director\"}\n",
      "\n",
      "[[ ## observation_1 ## ]]\n",
      "Failed to execute: name 'search' is not defined\n",
      "\n",
      "[[ ## thought_2 ## ]]\n",
      "Apologies once again for the confusion earlier. Let me try to retrieve the director of \"Batman: Mask of the Phantasm\" using the search_wikipedia tool.\n",
      "\n",
      "[[ ## tool_name_2 ## ]]\n",
      "search_wikipedia\n",
      "\n",
      "[[ ## tool_args_2 ## ]]\n",
      "{\"query\": \"Batman: Mask of the Phantasm director\"}\n",
      "\n",
      "[[ ## observation_2 ## ]]\n",
      "Failed to execute: name 'search' is not defined\n",
      "\n",
      "[[ ## thought_3 ## ]]\n",
      "Apologies once again for the confusion earlier. Let me try to retrieve the director of \"Batman: Mask of the Phantasm\" using the search_wikipedia tool.\n",
      "\n",
      "[[ ## tool_name_3 ## ]]\n",
      "search_wikipedia\n",
      "\n",
      "[[ ## tool_args_3 ## ]]\n",
      "{\"query\": \"Batman: Mask of the Phantasm director\"}\n",
      "\n",
      "[[ ## observation_3 ## ]]\n",
      "Failed to execute: name 'search' is not defined\n",
      "\n",
      "[[ ## thought_4 ## ]]\n",
      "Apologies once again for the confusion earlier. Let me try to retrieve the director of \"Batman: Mask of the Phantasm\" using the search_wikipedia tool.\n",
      "\n",
      "[[ ## tool_name_4 ## ]]\n",
      "search_wikipedia\n",
      "\n",
      "[[ ## tool_args_4 ## ]]\n",
      "{\"query\": \"Batman: Mask of the Phantasm director\"}\n",
      "\n",
      "[[ ## observation_4 ## ]]\n",
      "Failed to execute: name 'search' is not defined\n",
      "\n",
      "[[ ## thought_5 ## ]]\n",
      "Apologies once again for the confusion earlier. I need to find the director of \"Batman: Mask of the Phantasm\" to verify the claim. I will use the search_wikipedia tool to find this information.\n",
      "\n",
      "[[ ## tool_name_5 ## ]]\n",
      "search_wikipedia\n",
      "\n",
      "[[ ## tool_args_5 ## ]]\n",
      "{\"query\": \"Batman: Mask of the Phantasm director\"}\n",
      "\n",
      "[[ ## observation_5 ## ]]\n",
      "Failed to execute: name 'search' is not defined\n",
      "\n",
      "[[ ## thought_6 ## ]]\n",
      "Apologies once again for the confusion earlier. Let me try to retrieve the director of \"Batman: Mask of the Phantasm\" using the search_wikipedia tool.\n",
      "\n",
      "[[ ## tool_name_6 ## ]]\n",
      "search_wikipedia\n",
      "\n",
      "[[ ## tool_args_6 ## ]]\n",
      "{\"query\": \"Batman: Mask of the Phantasm director\"}\n",
      "\n",
      "[[ ## observation_6 ## ]]\n",
      "Failed to execute: name 'search' is not defined\n",
      "\n",
      "[[ ## thought_7 ## ]]\n",
      "Apologies for the repeated attempts. I need to find the director of \"Batman: Mask of the Phantasm\" to verify the claim. I will use the search_wikipedia tool to find this information.\n",
      "\n",
      "[[ ## tool_name_7 ## ]]\n",
      "search_wikipedia\n",
      "\n",
      "[[ ## tool_args_7 ## ]]\n",
      "{\"query\": \"Batman: Mask of the Phantasm director\"}\n",
      "\n",
      "[[ ## observation_7 ## ]]\n",
      "Failed to execute: name 'search' is not defined\n",
      "\n",
      "[[ ## thought_8 ## ]]\n",
      "Apologies for the repeated attempts. I need to find the director of \"Batman: Mask of the Phantasm\" to verify the claim. I will use the search_wikipedia tool to find this information.\n",
      "\n",
      "[[ ## tool_name_8 ## ]]\n",
      "search_wikipedia\n",
      "\n",
      "[[ ## tool_args_8 ## ]]\n",
      "{\"query\": \"Batman: Mask of the Phantasm director\"}\n",
      "\n",
      "[[ ## observation_8 ## ]]\n",
      "Failed to execute: name 'search' is not defined\n",
      "\n",
      "[[ ## thought_9 ## ]]\n",
      "Apologies for the repeated attempts. I need to find the director of \"Batman: Mask of the Phantasm\" to verify the claim. I will use the search_wikipedia tool to find this information.\n",
      "\n",
      "[[ ## tool_name_9 ## ]]\n",
      "search_wikipedia\n",
      "\n",
      "[[ ## tool_args_9 ## ]]\n",
      "{\"query\": \"Batman: Mask of the Phantasm director\"}\n",
      "\n",
      "[[ ## observation_9 ## ]]\n",
      "Failed to execute: name 'search' is not defined\n",
      "\n",
      "[[ ## thought_10 ## ]]\n",
      "Apologies for the repeated attempts. I need to find the director of \"Batman: Mask of the Phantasm\" to verify the claim. I will use the search_wikipedia tool to find this information.\n",
      "\n",
      "[[ ## tool_name_10 ## ]]\n",
      "search_wikipedia\n",
      "\n",
      "[[ ## tool_args_10 ## ]]\n",
      "{\"query\": \"Batman: Mask of the Phantasm director\"}\n",
      "\n",
      "[[ ## observation_10 ## ]]\n",
      "Failed to execute: name 'search' is not defined\n",
      "\n",
      "[[ ## thought_11 ## ]]\n",
      "Apologies for the confusion earlier. I need to find the director of \"Batman: Mask of the Phantasm\" to verify the claim. I will use the search_wikipedia tool to find this information.\n",
      "\n",
      "[[ ## tool_name_11 ## ]]\n",
      "search_wikipedia\n",
      "\n",
      "[[ ## tool_args_11 ## ]]\n",
      "{\"query\": \"Batman: Mask of the Phantasm director\"}\n",
      "\n",
      "[[ ## observation_11 ## ]]\n",
      "Failed to execute: name 'search' is not defined\n",
      "\n",
      "[[ ## thought_12 ## ]]\n",
      "Apologies for the confusion earlier. I need to find the director of \"Batman: Mask of the Phantasm\" to verify the claim. I will use the search_wikipedia tool to find this information.\n",
      "\n",
      "[[ ## tool_name_12 ## ]]\n",
      "search_wikipedia\n",
      "\n",
      "[[ ## tool_args_12 ## ]]\n",
      "{\"query\": \"Batman: Mask of the Phantasm director\"}\n",
      "\n",
      "[[ ## observation_12 ## ]]\n",
      "Failed to execute: name 'search' is not defined\n",
      "\n",
      "[[ ## thought_13 ## ]]\n",
      "Apologies for the confusion earlier. I need to find the director of \"Batman: Mask of the Phantasm\" to verify the claim. I will use the search_wikipedia tool to find this information.\n",
      "\n",
      "[[ ## tool_name_13 ## ]]\n",
      "search_wikipedia\n",
      "\n",
      "[[ ## tool_args_13 ## ]]\n",
      "{\"query\": \"Batman: Mask of the Phantasm director\"}\n",
      "\n",
      "[[ ## observation_13 ## ]]\n",
      "Failed to execute: name 'search' is not defined\n",
      "\n",
      "[[ ## thought_14 ## ]]\n",
      "Apologies for the confusion earlier. I need to find the director of \"Batman: Mask of the Phantasm\" to verify the claim. I will use the search_wikipedia tool to find this information.\n",
      "\n",
      "[[ ## tool_name_14 ## ]]\n",
      "search_wikipedia\n",
      "\n",
      "[[ ## tool_args_14 ## ]]\n",
      "{\"query\": \"Batman: Mask of the Phantasm director\"}\n",
      "\n",
      "[[ ## observation_14 ## ]]\n",
      "Failed to execute: name 'search' is not defined\n",
      "\n",
      "[[ ## thought_15 ## ]]\n",
      "Apologies for the repeated attempts. I need to find the director of \"Batman: Mask of the Phantasm\" to verify the claim. I will use the search_wikipedia tool to find this information.\n",
      "\n",
      "[[ ## tool_name_15 ## ]]\n",
      "search_wikipedia\n",
      "\n",
      "[[ ## tool_args_15 ## ]]\n",
      "{\"query\": \"Batman: Mask of the Phantasm director\"}\n",
      "\n",
      "[[ ## observation_15 ## ]]\n",
      "Failed to execute: name 'search' is not defined\n",
      "\n",
      "[[ ## thought_16 ## ]]\n",
      "Apologies for the repeated attempts. I need to find the director of \"Batman: Mask of the Phantasm\" to verify the claim. I will use the search_wikipedia tool to find this information.\n",
      "\n",
      "[[ ## tool_name_16 ## ]]\n",
      "search_wikipedia\n",
      "\n",
      "[[ ## tool_args_16 ## ]]\n",
      "{\"query\": \"Batman: Mask of the Phantasm director\"}\n",
      "\n",
      "[[ ## observation_16 ## ]]\n",
      "Failed to execute: name 'search' is not defined\n",
      "\n",
      "[[ ## thought_17 ## ]]\n",
      "Apologies for the repeated attempts. I need to find the director of \"Batman: Mask of the Phantasm\" to verify the claim. I will use the search_wikipedia tool to find this information.\n",
      "\n",
      "[[ ## tool_name_17 ## ]]\n",
      "search_wikipedia\n",
      "\n",
      "[[ ## tool_args_17 ## ]]\n",
      "{\"query\": \"Batman: Mask of the Phantasm director\"}\n",
      "\n",
      "[[ ## observation_17 ## ]]\n",
      "Failed to execute: name 'search' is not defined\n",
      "\n",
      "[[ ## thought_18 ## ]]\n",
      "Apologies for the repeated attempts. I need to find the director of \"Batman: Mask of the Phantasm\" to verify the claim. I will use the search_wikipedia tool to find this information.\n",
      "\n",
      "[[ ## tool_name_18 ## ]]\n",
      "search_wikipedia\n",
      "\n",
      "[[ ## tool_args_18 ## ]]\n",
      "{\"query\": \"Batman: Mask of the Phantasm director\"}\n",
      "\n",
      "[[ ## observation_18 ## ]]\n",
      "Failed to execute: name 'search' is not defined\n",
      "\n",
      "[[ ## thought_19 ## ]]\n",
      "Apologies for the repeated attempts. I need to find the director of \"Batman: Mask of the Phantasm\" to verify the claim. I will use the search_wikipedia tool to find this information.\n",
      "\n",
      "[[ ## tool_name_19 ## ]]\n",
      "search_wikipedia\n",
      "\n",
      "[[ ## tool_args_19 ## ]]\n",
      "{\"query\": \"Batman: Mask of the Phantasm director\"}\n",
      "\n",
      "[[ ## observation_19 ## ]]\n",
      "Failed to execute: name 'search' is not defined\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## titles ## ]]` (must be formatted as a valid Python list[str]), and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## reasoning ## ]]\n",
      "The claim states that the director of \"Batman: Mask of the Phantasm\" also directed \"Avengers Assemble\". After attempting to find the director of \"Batman: Mask of the Phantasm\" using the search_wikipedia tool, I was unable to retrieve the information due to an error. However, based on the information available, I can still provide relevant Wikipedia titles to verify or refute the claim.\n",
      "\n",
      "[[ ## titles ## ]]\n",
      "[\"Batman: Mask of the Phantasm\", \"Avengers Assemble (TV series)\", \"List of Batman animated television series directors\", \"List of Avengers Assemble episodes\"]\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dspy.inspect_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da42b72a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "916ae5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/07 18:45:36 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "RUNNING WITH THE FOLLOWING LIGHT AUTO RUN SETTINGS:\n",
      "num_trials: 7\n",
      "minibatch: False\n",
      "num_candidates: 3\n",
      "valset size: 16\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\u001b[93m\u001b[1mProjected Language Model (LM) Calls\u001b[0m\n",
      "\n",
      "Based on the parameters you have set, the maximum number of LM calls is projected as follows:\n",
      "\n",
      "\u001b[93m- Prompt Generation: \u001b[94m\u001b[1m10\u001b[0m\u001b[93m data summarizer calls + \u001b[94m\u001b[1m3\u001b[0m\u001b[93m * \u001b[94m\u001b[1m2\u001b[0m\u001b[93m lm calls in program + (\u001b[94m\u001b[1m3\u001b[0m\u001b[93m) lm calls in program-aware proposer = \u001b[94m\u001b[1m19\u001b[0m\u001b[93m prompt model calls\u001b[0m\n",
      "\u001b[93m- Program Evaluation: \u001b[94m\u001b[1m16\u001b[0m\u001b[93m examples in val set * \u001b[94m\u001b[1m7\u001b[0m\u001b[93m batches = \u001b[94m\u001b[1m112\u001b[0m\u001b[93m LM program calls\u001b[0m\n",
      "\n",
      "\u001b[93m\u001b[1mEstimated Cost Calculation:\u001b[0m\n",
      "\n",
      "\u001b[93mTotal Cost = (Number of calls to task model * (Avg Input Token Length per Call * Task Model Price per Input Token + Avg Output Token Length per Call * Task Model Price per Output Token) \n",
      "            + (Number of program calls * (Avg Input Token Length per Call * Task Prompt Price per Input Token + Avg Output Token Length per Call * Prompt Model Price per Output Token).\u001b[0m\n",
      "\n",
      "For a preliminary estimate of potential costs, we recommend you perform your own calculations based on the task\n",
      "and prompt models you intend to use. If the projected costs exceed your budget or expectations, you may consider:\n",
      "\n",
      "\u001b[93m- Reducing the number of trials (`num_trials`), the size of the valset, or the number of LM calls in your program.\u001b[0m\n",
      "\u001b[93m- Using a cheaper task model to optimize the prompt.\u001b[0m\n",
      "\u001b[93m- Setting `minibatch=True` if you haven't already.\u001b[0m\n",
      "\n",
      "To proceed with the execution of this program, please confirm by typing \u001b[94m'y'\u001b[0m for yes or \u001b[94m'n'\u001b[0m for no.\n",
      "\n",
      "If you would like to bypass this confirmation step in future executions, set the \u001b[93m`requires_permission_to_run`\u001b[0m flag to \u001b[93m`False`\u001b[0m when calling compile.\n",
      "\n",
      "\u001b[93mAwaiting your input...\u001b[0m\n",
      "\n",
      "Do you wish to continue? (y/n):  y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/07 18:45:41 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "==> STEP 1: BOOTSTRAP FEWSHOT EXAMPLES <==\n",
      "2025/01/07 18:45:41 INFO dspy.teleprompt.mipro_optimizer_v2: These will be used as few-shot example candidates for our program and for creating instructions.\n",
      "\n",
      "2025/01/07 18:45:41 INFO dspy.teleprompt.mipro_optimizer_v2: Bootstrapping N=3 sets of demonstrations...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapping set 1/3\n",
      "Bootstrapping set 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                                                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|███████████████████████████████████████▎                                                                                                                     | 1/4 [00:35<01:46, 35.62s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**pred titles ** ['Chris Noonan', 'Miss Potter', 'Babe (film)', 'Academy Awards']\n",
      "'\n",
      "'\n",
      "---> gold titles ['Academy Award for Best Director', 'Chris Noonan', 'Miss Potter']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/07 18:49:42 ERROR dspy.teleprompt.bootstrap: Failed to run or to evaluate example Example({'claim': '1990 Film that Khiladiyon Ka Khiladi is loosely based on stars this actor who is best known for martial arts action films.', 'titles': ['Jean-Claude Van Damme', 'Lionheart (1990 film)', 'Khiladiyon Ka Khiladi']}) (input_keys={'claim'}) with <function top5_recall at 0x7fb85065d5a0> due to 'list' object has no attribute 'items'.\n",
      "\n",
      " 50%|██████████████████████████████████████████████████████████████████████████████                                                                              | 2/4 [04:01<04:31, 135.57s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.33 / 8 (4.2%):  40%|█████████████████████████████████████████████████▏                                                                         | 8/20 [07:35<11:23, 56.99s/it]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                       | 3/4 [04:39<01:31, 91.08s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**pred titles ** ['Reynella railway station', 'Seaford railway line']\n",
      "'\n",
      "'\n",
      "---> gold titles ['Willunga, South Australia', 'Reynella railway station', 'Willunga railway line']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [05:23<00:00, 80.99s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**pred titles ** ['Gracie Humaitá', 'Royler Gracie', 'Romero Cavalcanti', 'Brazilian jiu-jitsu', 'Gracie family']\n",
      "'\n",
      "'\n",
      "---> gold titles ['Royler Gracie', 'Rodrigo Medeiros', 'Rolls Gracie']\n",
      "Bootstrapped 0 full traces after 3 examples for up to 1 rounds, amounting to 4 attempts.\n",
      "Bootstrapping set 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████████████████████████████████▎                                                                                                                     | 1/4 [00:00<00:01,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**pred titles ** ['Chris Noonan', 'Miss Potter', 'Babe (film)', 'Academy Awards']\n",
      "'\n",
      "'\n",
      "---> gold titles ['Academy Award for Best Director', 'Chris Noonan', 'Miss Potter']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/07 18:51:06 ERROR dspy.teleprompt.bootstrap: Failed to run or to evaluate example Example({'claim': '1990 Film that Khiladiyon Ka Khiladi is loosely based on stars this actor who is best known for martial arts action films.', 'titles': ['Jean-Claude Van Damme', 'Lionheart (1990 film)', 'Khiladiyon Ka Khiladi']}) (input_keys={'claim'}) with <function top5_recall at 0x7fb85065d5a0> due to 'list' object has no attribute 'items'.\n",
      " 75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                       | 3/4 [00:01<00:00,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**pred titles ** ['Reynella railway station', 'Seaford railway line']\n",
      "'\n",
      "'\n",
      "---> gold titles ['Willunga, South Australia', 'Reynella railway station', 'Willunga railway line']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:01<00:00,  2.57it/s]\n",
      "2025/01/07 18:51:06 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "==> STEP 2: PROPOSE INSTRUCTION CANDIDATES <==\n",
      "2025/01/07 18:51:06 INFO dspy.teleprompt.mipro_optimizer_v2: We will use the few-shot examples from the previous step, a generated dataset summary, a summary of the program code, and a randomly selected prompting tip to propose instructions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**pred titles ** ['Gracie Humaitá', 'Royler Gracie', 'Romero Cavalcanti', 'Brazilian jiu-jitsu', 'Gracie family']\n",
      "'\n",
      "'\n",
      "---> gold titles ['Royler Gracie', 'Rodrigo Medeiros', 'Rolls Gracie']\n",
      "Bootstrapped 0 full traces after 3 examples for up to 1 rounds, amounting to 4 attempts.\n",
      "SOURCE CODE: StringSignature(claim, trajectory -> next_thought, next_tool_name, next_tool_args\n",
      "    instructions=\"Find all Wikipedia titles relevant to verifying (or refuting) the claim.\\n\\nYou will be given `claim` and your goal is to finish with `titles`.\\n\\nTo do this, you will interleave Thought, Tool Name, and Tool Args, and receive a resulting Observation.\\n\\nThought can reason about the current situation, and Tool Name can be the following types:\\n\\n(1) search_wikipedia, whose description is <desc>Returns top-5 results and then the titles of the top-5 to top-30 results.</desc>. It takes arguments {'query': 'str'} in JSON format.\\n(2) lookup_wikipedia, whose description is <desc>Returns the text of the Wikipedia page, if it exists.</desc>. It takes arguments {'title': 'str'} in JSON format.\\n(3) finish, whose description is <desc>Signals that the final outputs, i.e. `titles`, are now available and marks the task as complete.</desc>. It takes arguments {} in JSON format.\"\n",
      "    claim = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Claim:', 'desc': '${claim}'})\n",
      "    trajectory = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Trajectory:', 'desc': '${trajectory}'})\n",
      "    next_thought = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Next Thought:', 'desc': '${next_thought}'})\n",
      "    next_tool_name = Field(annotation=Literal['search_wikipedia', 'lookup_wikipedia', 'finish'] required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Next Tool Name:', 'desc': '${next_tool_name}'})\n",
      "    next_tool_args = Field(annotation=dict[str, Any] required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Next Tool Args:', 'desc': '${next_tool_args}'})\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "StringSignature(claim, trajectory -> reasoning, titles\n",
      "    instructions='Find all Wikipedia titles relevant to verifying (or refuting) the claim.'\n",
      "    claim = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Claim:', 'desc': '${claim}'})\n",
      "    trajectory = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Trajectory:', 'desc': '${trajectory}'})\n",
      "    reasoning = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${reasoning}', '__dspy_field_type': 'output'})\n",
      "    titles = Field(annotation=list[str] required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Titles:', 'desc': '${titles}'})\n",
      ")\n",
      "\n",
      "class ReAct(Module):\n",
      "    def __init__(self, signature, tools: list[Callable], max_iters=5):\n",
      "        \"\"\"\n",
      "        `tools` is either a list of functions, callable classes, or `dspy.Tool` instances.\n",
      "        \"\"\"\n",
      "\n",
      "        self.signature = signature = ensure_signature(signature)\n",
      "        self.max_iters = max_iters\n",
      "\n",
      "        tools = [t if isinstance(t, Tool) or hasattr(t, \"input_variable\") else Tool(t) for t in tools]\n",
      "        tools = {tool.name: tool for tool in tools}\n",
      "\n",
      "        inputs = \", \".join([f\"`{k}`\" for k in signature.input_fields.keys()])\n",
      "        outputs = \", \".join([f\"`{k}`\" for k in signature.output_fields.keys()])\n",
      "        instr = [f\"{signature.instructions}\\n\"] if signature.instructions else []\n",
      "\n",
      "        instr.extend(\n",
      "            [\n",
      "                f\"You will be given {inputs} and your goal is to finish with {outputs}.\\n\",\n",
      "                \"To do this, you will interleave Thought, Tool Name, and Tool Args, and receive a resulting Observation.\\n\",\n",
      "                \"Thought can reason about the current situation, and Tool Name can be the following types:\\n\",\n",
      "            ]\n",
      "        )\n",
      "\n",
      "        finish_desc = (\n",
      "            f\"Signals that the final outputs, i.e. {outputs}, are now available and marks the task as complete.\"\n",
      "        )\n",
      "        finish_args = {}  # k: v.annotation for k, v in signature.output_fields.items()}\n",
      "        tools[\"finish\"] = Tool(func=lambda **kwargs: \"Completed.\", name=\"finish\", desc=finish_desc, args=finish_args)\n",
      "\n",
      "        for idx, tool in enumerate(tools.values()):\n",
      "            args = tool.args if hasattr(tool, \"args\") else str({tool.input_variable: str})\n",
      "            desc = (f\", whose description is <desc>{tool.desc}</desc>.\" if tool.desc else \".\").replace(\"\\n\", \"  \")\n",
      "            desc += f\" It takes arguments {args} in JSON format.\"\n",
      "            instr.append(f\"({idx+1}) {tool.name}{desc}\")\n",
      "\n",
      "        react_signature = (\n",
      "            dspy.Signature({**signature.input_fields}, \"\\n\".join(instr))\n",
      "            .append(\"trajectory\", dspy.InputField(), type_=str)\n",
      "            .append(\"next_thought\", dspy.OutputField(), type_=str)\n",
      "            .append(\"next_tool_name\", dspy.OutputField(), type_=Literal[tuple(tools.keys())])\n",
      "            .append(\"next_tool_args\", dspy.OutputField(), type_=dict[str, Any])\n",
      "        )\n",
      "\n",
      "        fallback_signature = dspy.Signature(\n",
      "            {**signature.input_fields, **signature.output_fields}, signature.instructions\n",
      "        ).append(\"trajectory\", dspy.InputField(), type_=str)\n",
      "\n",
      "        self.tools = tools\n",
      "        self.react = dspy.Predict(react_signature)\n",
      "        self.extract = dspy.ChainOfThought(fallback_signature)\n",
      "\n",
      "    def forward(self, **input_args):\n",
      "        def format(trajectory: dict[str, Any], last_iteration: bool):\n",
      "            adapter = dspy.settings.adapter or dspy.ChatAdapter()\n",
      "            trajectory_signature = dspy.Signature(f\"{', '.join(trajectory.keys())} -> x\")\n",
      "            return adapter.format_fields(trajectory_signature, trajectory, role=\"user\")\n",
      "\n",
      "        trajectory = {}\n",
      "        for idx in range(self.max_iters):\n",
      "            pred = self.react(**input_args, trajectory=format(trajectory, last_iteration=(idx == self.max_iters - 1)))\n",
      "\n",
      "            trajectory[f\"thought_{idx}\"] = pred.next_thought\n",
      "            trajectory[f\"tool_name_{idx}\"] = pred.next_tool_name\n",
      "            trajectory[f\"tool_args_{idx}\"] = pred.next_tool_args\n",
      "\n",
      "            try:\n",
      "                trajectory[f\"observation_{idx}\"] = self.tools[pred.next_tool_name](**pred.next_tool_args)\n",
      "            except Exception as e:\n",
      "                trajectory[f\"observation_{idx}\"] = f\"Failed to execute: {e}\"\n",
      "\n",
      "            if pred.next_tool_name == \"finish\":\n",
      "                break\n",
      "\n",
      "        extract = self.extract(**input_args, trajectory=format(trajectory, last_iteration=False))\n",
      "        return dspy.Prediction(trajectory=trajectory, **extract)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/07 18:51:18 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "Proposing instructions...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA SUMMARY: The dataset comprises concise claims connecting topics or individuals to specific details or events, indicating potential use for fact-checking or knowledge validation. Each claim is associated with titles that may act as evidence or context, and the dataset covers a wide range of domains including film, railway routes, and martial arts. The brevity and clarity of the claims suggest their use in tasks requiring direct factual statements.\n",
      "Using a randomly generated configuration for our grounded proposer.\n",
      "Selected tip: creative\n",
      "PROGRAM DESCRIPTION: This program is designed to solve the task of fact-checking or verifying a given claim using Wikipedia as a source of information. The program uses a pipeline that interacts with language models to generate a sequence of thoughts, tool names, and tool arguments, which are then used to retrieve relevant information from Wikipedia.\n",
      "\n",
      "The program begins by defining a `StringSignature` for the task, which includes the claim to be verified, a trajectory of thoughts and actions, and the output fields for the next thought, the name of the next tool to be used, and the arguments for that tool. The `StringSignature` also includes instructions for the task and descriptions of the available tools.\n",
      "\n",
      "The program then defines a `ReAct` module, which takes in the `StringSignature` and a list of tools as input. The `ReAct` module initializes the tools and creates a new `Signature` object that includes the input fields, instructions, and descriptions of the available tools. It also defines a `finish` tool, which signals that the task is complete and marks the final outputs as available.\n",
      "\n",
      "The `ReAct` module then uses a `Predict` function to generate a sequence of thoughts, tool names, and tool arguments based on the input claim and trajectory. It then executes each tool in the sequence and stores the resulting observations in a trajectory dictionary. If the `finish` tool is used, the task is marked as complete and the final outputs are returned.\n",
      "\n",
      "Overall, this program uses a combination of language models and Wikipedia to verify or refute a given claim. It generates a sequence of thoughts and actions to retrieve relevant information from Wikipedia, and then uses that information to make a determination about the claim.\n",
      "task_demos \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-01-07T18:51:43.105876]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `dataset_description` (str): A description of the dataset that we are using.\n",
      "2. `program_code` (str): Language model program designed to solve a particular task.\n",
      "3. `program_description` (str): Summary of the task the program is designed to solve, and how it goes about solving it.\n",
      "4. `module` (str): The module to create an instruction for.\n",
      "5. `task_demos` (str): Example inputs/outputs of our module.\n",
      "6. `basic_instruction` (str): Basic instruction.\n",
      "7. `tip` (str): A suggestion for how to go about generating the new instruction.\n",
      "\n",
      "Your output fields are:\n",
      "1. `proposed_instruction` (str): Propose an instruction that will be used to prompt a Language Model to perform this task.\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## dataset_description ## ]]\n",
      "{dataset_description}\n",
      "\n",
      "[[ ## program_code ## ]]\n",
      "{program_code}\n",
      "\n",
      "[[ ## program_description ## ]]\n",
      "{program_description}\n",
      "\n",
      "[[ ## module ## ]]\n",
      "{module}\n",
      "\n",
      "[[ ## task_demos ## ]]\n",
      "{task_demos}\n",
      "\n",
      "[[ ## basic_instruction ## ]]\n",
      "{basic_instruction}\n",
      "\n",
      "[[ ## tip ## ]]\n",
      "{tip}\n",
      "\n",
      "[[ ## proposed_instruction ## ]]\n",
      "{proposed_instruction}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        Use the information below to learn about a task that we are trying to solve using calls to an LM, then generate a new instruction that will be used to prompt a Language Model to better solve the task.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## dataset_description ## ]]\n",
      "The dataset comprises concise claims connecting topics or individuals to specific details or events, indicating potential use for fact-checking or knowledge validation. Each claim is associated with titles that may act as evidence or context, and the dataset covers a wide range of domains including film, railway routes, and martial arts. The brevity and clarity of the claims suggest their use in tasks requiring direct factual statements.\n",
      "\n",
      "[[ ## program_code ## ]]\n",
      "StringSignature(claim, trajectory -> next_thought, next_tool_name, next_tool_args\n",
      "    instructions=\"Find all Wikipedia titles relevant to verifying (or refuting) the claim.\\n\\nYou will be given `claim` and your goal is to finish with `titles`.\\n\\nTo do this, you will interleave Thought, Tool Name, and Tool Args, and receive a resulting Observation.\\n\\nThought can reason about the current situation, and Tool Name can be the following types:\\n\\n(1) search_wikipedia, whose description is <desc>Returns top-5 results and then the titles of the top-5 to top-30 results.</desc>. It takes arguments {'query': 'str'} in JSON format.\\n(2) lookup_wikipedia, whose description is <desc>Returns the text of the Wikipedia page, if it exists.</desc>. It takes arguments {'title': 'str'} in JSON format.\\n(3) finish, whose description is <desc>Signals that the final outputs, i.e. `titles`, are now available and marks the task as complete.</desc>. It takes arguments {} in JSON format.\"\n",
      "    claim = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Claim:', 'desc': '${claim}'})\n",
      "    trajectory = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Trajectory:', 'desc': '${trajectory}'})\n",
      "    next_thought = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Next Thought:', 'desc': '${next_thought}'})\n",
      "    next_tool_name = Field(annotation=Literal['search_wikipedia', 'lookup_wikipedia', 'finish'] required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Next Tool Name:', 'desc': '${next_tool_name}'})\n",
      "    next_tool_args = Field(annotation=dict[str, Any] required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Next Tool Args:', 'desc': '${next_tool_args}'})\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "StringSignature(claim, trajectory -> reasoning, titles\n",
      "    instructions='Find all Wikipedia titles relevant to verifying (or refuting) the claim.'\n",
      "    claim = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Claim:', 'desc': '${claim}'})\n",
      "    trajectory = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Trajectory:', 'desc': '${trajectory}'})\n",
      "    reasoning = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${reasoning}', '__dspy_field_type': 'output'})\n",
      "    titles = Field(annotation=list[str] required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Titles:', 'desc': '${titles}'})\n",
      ")\n",
      "\n",
      "class ReAct(Module):\n",
      "    def __init__(self, signature, tools: list[Callable], max_iters=5):\n",
      "        \"\"\"\n",
      "        `tools` is either a list of functions, callable classes, or `dspy.Tool` instances.\n",
      "        \"\"\"\n",
      "\n",
      "        self.signature = signature = ensure_signature(signature)\n",
      "        self.max_iters = max_iters\n",
      "\n",
      "        tools = [t if isinstance(t, Tool) or hasattr(t, \"input_variable\") else Tool(t) for t in tools]\n",
      "        tools = {tool.name: tool for tool in tools}\n",
      "\n",
      "        inputs = \", \".join([f\"`{k}`\" for k in signature.input_fields.keys()])\n",
      "        outputs = \", \".join([f\"`{k}`\" for k in signature.output_fields.keys()])\n",
      "        instr = [f\"{signature.instructions}\\n\"] if signature.instructions else []\n",
      "\n",
      "        instr.extend(\n",
      "            [\n",
      "                f\"You will be given {inputs} and your goal is to finish with {outputs}.\\n\",\n",
      "                \"To do this, you will interleave Thought, Tool Name, and Tool Args, and receive a resulting Observation.\\n\",\n",
      "                \"Thought can reason about the current situation, and Tool Name can be the following types:\\n\",\n",
      "            ]\n",
      "        )\n",
      "\n",
      "        finish_desc = (\n",
      "            f\"Signals that the final outputs, i.e. {outputs}, are now available and marks the task as complete.\"\n",
      "        )\n",
      "        finish_args = {}  # k: v.annotation for k, v in signature.output_fields.items()}\n",
      "        tools[\"finish\"] = Tool(func=lambda **kwargs: \"Completed.\", name=\"finish\", desc=finish_desc, args=finish_args)\n",
      "\n",
      "        for idx, tool in enumerate(tools.values()):\n",
      "            args = tool.args if hasattr(tool, \"args\") else str({tool.input_variable: str})\n",
      "            desc = (f\", whose description is <desc>{tool.desc}</desc>.\" if tool.desc else \".\").replace(\"\\n\", \"  \")\n",
      "            desc += f\" It takes arguments {args} in JSON format.\"\n",
      "            instr.append(f\"({idx+1}) {tool.name}{desc}\")\n",
      "\n",
      "        react_signature = (\n",
      "            dspy.Signature({**signature.input_fields}, \"\\n\".join(instr))\n",
      "            .append(\"trajectory\", dspy.InputField(), type_=str)\n",
      "            .append(\"next_thought\", dspy.OutputField(), type_=str)\n",
      "            .append(\"next_tool_name\", dspy.OutputField(), type_=Literal[tuple(tools.keys())])\n",
      "            .append(\"next_tool_args\", dspy.OutputField(), type_=dict[str, Any])\n",
      "        )\n",
      "\n",
      "        fallback_signature = dspy.Signature(\n",
      "            {**signature.input_fields, **signature.output_fields}, signature.instructions\n",
      "        ).append(\"trajectory\", dspy.InputField(), type_=str)\n",
      "\n",
      "        self.tools = tools\n",
      "        self.react = dspy.Predict(react_signature)\n",
      "        self.extract = dspy.ChainOfThought(fallback_signature)\n",
      "\n",
      "    def forward(self, **input_args):\n",
      "        def format(trajectory: dict[str, Any], last_iteration: bool):\n",
      "            adapter = dspy.settings.adapter or dspy.ChatAdapter()\n",
      "            trajectory_signature = dspy.Signature(f\"{', '.join(trajectory.keys())} -> x\")\n",
      "            return adapter.format_fields(trajectory_signature, trajectory, role=\"user\")\n",
      "\n",
      "        trajectory = {}\n",
      "        for idx in range(self.max_iters):\n",
      "            pred = self.react(**input_args, trajectory=format(trajectory, last_iteration=(idx == self.max_iters - 1)))\n",
      "\n",
      "            trajectory[f\"thought_{idx}\"] = pred.next_thought\n",
      "            trajectory[f\"tool_name_{idx}\"] = pred.next_tool_name\n",
      "            trajectory[f\"tool_args_{idx}\"] = pred.next_tool_args\n",
      "\n",
      "            try:\n",
      "                trajectory[f\"observation_{idx}\"] = self.tools[pred.next_tool_name](**pred.next_tool_args)\n",
      "            except Exception as e:\n",
      "                trajectory[f\"observation_{idx}\"] = f\"Failed to execute: {e}\"\n",
      "\n",
      "            if pred.next_tool_name == \"finish\":\n",
      "                break\n",
      "\n",
      "        extract = self.extract(**input_args, trajectory=format(trajectory, last_iteration=False))\n",
      "        return dspy.Prediction(trajectory=trajectory, **extract)\n",
      "\n",
      "\n",
      "[[ ## program_description ## ]]\n",
      "This program is designed to solve the task of fact-checking or verifying a given claim using Wikipedia as a source of information. The program uses a pipeline that interacts with language models to generate a sequence of thoughts, tool names, and tool arguments, which are then used to retrieve relevant information from Wikipedia.\n",
      "\n",
      "The program begins by defining a `StringSignature` for the task, which includes the claim to be verified, a trajectory of thoughts and actions, and the output fields for the next thought, the name of the next tool to be used, and the arguments for that tool. The `StringSignature` also includes instructions for the task and descriptions of the available tools.\n",
      "\n",
      "The program then defines a `ReAct` module, which takes in the `StringSignature` and a list of tools as input. The `ReAct` module initializes the tools and creates a new `Signature` object that includes the input fields, instructions, and descriptions of the available tools. It also defines a `finish` tool, which signals that the task is complete and marks the final outputs as available.\n",
      "\n",
      "The `ReAct` module then uses a `Predict` function to generate a sequence of thoughts, tool names, and tool arguments based on the input claim and trajectory. It then executes each tool in the sequence and stores the resulting observations in a trajectory dictionary. If the `finish` tool is used, the task is marked as complete and the final outputs are returned.\n",
      "\n",
      "Overall, this program uses a combination of language models and Wikipedia to verify or refute a given claim. It generates a sequence of thoughts and actions to retrieve relevant information from Wikipedia, and then uses that information to make a determination about the claim.\n",
      "\n",
      "[[ ## module ## ]]\n",
      "Predict(claim, trajectory) -> next_thought, next_tool_name, next_tool_args\n",
      "\n",
      "[[ ## task_demos ## ]]\n",
      "\n",
      "\n",
      "[[ ## basic_instruction ## ]]\n",
      "Find all Wikipedia titles relevant to verifying (or refuting) the claim.\n",
      "\n",
      "You will be given `claim` and your goal is to finish with `titles`.\n",
      "\n",
      "To do this, you will interleave Thought, Tool Name, and Tool Args, and receive a resulting Observation.\n",
      "\n",
      "Thought can reason about the current situation, and Tool Name can be the following types:\n",
      "\n",
      "(1) search_wikipedia, whose description is <desc>Returns top-5 results and then the titles of the top-5 to top-30 results.</desc>. It takes arguments {'query': 'str'} in JSON format.\n",
      "(2) lookup_wikipedia, whose description is <desc>Returns the text of the Wikipedia page, if it exists.</desc>. It takes arguments {'title': 'str'} in JSON format.\n",
      "(3) finish, whose description is <desc>Signals that the final outputs, i.e. `titles`, are now available and marks the task as complete.</desc>. It takes arguments {} in JSON format.\n",
      "\n",
      "[[ ## tip ## ]]\n",
      "Don't be afraid to be creative when creating the new instruction!\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## proposed_instruction ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## proposed_instruction ## ]]\n",
      "To verify the given claim, identify the key entities or events mentioned within it. Then, generate a list of potential Wikipedia search queries that could yield relevant information about these entities or events. Utilize the `search_wikipedia` tool to execute these queries and retrieve the top-5 results. Extract the titles of the top-5 to top-30 results from these search results. If necessary, use the `lookup_wikipedia` tool to gather more detailed information from specific Wikipedia pages. Once you have gathered sufficient evidence, use the `finish` tool to signal that the task is complete and provide the final list of relevant Wikipedia titles.\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "PROPOSED INSTRUCTION: To verify the given claim, identify the key entities or events mentioned within it. Then, generate a list of potential Wikipedia search queries that could yield relevant information about these entities or events. Utilize the `search_wikipedia` tool to execute these queries and retrieve the top-5 results. Extract the titles of the top-5 to top-30 results from these search results. If necessary, use the `lookup_wikipedia` tool to gather more detailed information from specific Wikipedia pages. Once you have gathered sufficient evidence, use the `finish` tool to signal that the task is complete and provide the final list of relevant Wikipedia titles.\n",
      "Using a randomly generated configuration for our grounded proposer.\n",
      "Selected tip: creative\n",
      "PROGRAM DESCRIPTION: This program is designed to solve the task of fact-checking or verifying a given claim using Wikipedia as a source of information. The program uses a pipeline that interacts with language models to generate a sequence of thoughts, tool names, and tool arguments, which are then used to retrieve relevant information from Wikipedia.\n",
      "\n",
      "The program begins by defining a `StringSignature` for the task, which includes the claim to be verified, a trajectory of thoughts and actions, and the output fields for the next thought, the name of the next tool to be used, and the arguments for that tool. The `StringSignature` also includes instructions for the task and descriptions of the available tools.\n",
      "\n",
      "The program then defines a `ReAct` module, which takes in the `StringSignature` and a list of tools as input. The `ReAct` module initializes the tools and creates a new `Signature` object that includes the input fields, instructions, and descriptions of the available tools. It also defines a `finish` tool, which signals that the task is complete and marks the final outputs as available.\n",
      "\n",
      "The `ReAct` module then uses a `Predict` function to generate a sequence of thoughts, tool names, and tool arguments based on the input claim and trajectory. It then executes each tool in the sequence and stores the resulting observations in a trajectory dictionary. If the `finish` tool is used, the task is marked as complete and the final outputs are returned.\n",
      "\n",
      "Overall, this program uses a combination of language models and Wikipedia to verify or refute a given claim. It generates a sequence of thoughts and actions to retrieve relevant information from Wikipedia, and then uses that information to make a determination about the claim.\n",
      "task_demos \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-01-07T18:51:43.115233]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `dataset_description` (str): A description of the dataset that we are using.\n",
      "2. `program_code` (str): Language model program designed to solve a particular task.\n",
      "3. `program_description` (str): Summary of the task the program is designed to solve, and how it goes about solving it.\n",
      "4. `module` (str): The module to create an instruction for.\n",
      "5. `task_demos` (str): Example inputs/outputs of our module.\n",
      "6. `basic_instruction` (str): Basic instruction.\n",
      "7. `tip` (str): A suggestion for how to go about generating the new instruction.\n",
      "\n",
      "Your output fields are:\n",
      "1. `proposed_instruction` (str): Propose an instruction that will be used to prompt a Language Model to perform this task.\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## dataset_description ## ]]\n",
      "{dataset_description}\n",
      "\n",
      "[[ ## program_code ## ]]\n",
      "{program_code}\n",
      "\n",
      "[[ ## program_description ## ]]\n",
      "{program_description}\n",
      "\n",
      "[[ ## module ## ]]\n",
      "{module}\n",
      "\n",
      "[[ ## task_demos ## ]]\n",
      "{task_demos}\n",
      "\n",
      "[[ ## basic_instruction ## ]]\n",
      "{basic_instruction}\n",
      "\n",
      "[[ ## tip ## ]]\n",
      "{tip}\n",
      "\n",
      "[[ ## proposed_instruction ## ]]\n",
      "{proposed_instruction}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        Use the information below to learn about a task that we are trying to solve using calls to an LM, then generate a new instruction that will be used to prompt a Language Model to better solve the task.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## dataset_description ## ]]\n",
      "The dataset comprises concise claims connecting topics or individuals to specific details or events, indicating potential use for fact-checking or knowledge validation. Each claim is associated with titles that may act as evidence or context, and the dataset covers a wide range of domains including film, railway routes, and martial arts. The brevity and clarity of the claims suggest their use in tasks requiring direct factual statements.\n",
      "\n",
      "[[ ## program_code ## ]]\n",
      "StringSignature(claim, trajectory -> next_thought, next_tool_name, next_tool_args\n",
      "    instructions=\"Find all Wikipedia titles relevant to verifying (or refuting) the claim.\\n\\nYou will be given `claim` and your goal is to finish with `titles`.\\n\\nTo do this, you will interleave Thought, Tool Name, and Tool Args, and receive a resulting Observation.\\n\\nThought can reason about the current situation, and Tool Name can be the following types:\\n\\n(1) search_wikipedia, whose description is <desc>Returns top-5 results and then the titles of the top-5 to top-30 results.</desc>. It takes arguments {'query': 'str'} in JSON format.\\n(2) lookup_wikipedia, whose description is <desc>Returns the text of the Wikipedia page, if it exists.</desc>. It takes arguments {'title': 'str'} in JSON format.\\n(3) finish, whose description is <desc>Signals that the final outputs, i.e. `titles`, are now available and marks the task as complete.</desc>. It takes arguments {} in JSON format.\"\n",
      "    claim = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Claim:', 'desc': '${claim}'})\n",
      "    trajectory = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Trajectory:', 'desc': '${trajectory}'})\n",
      "    next_thought = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Next Thought:', 'desc': '${next_thought}'})\n",
      "    next_tool_name = Field(annotation=Literal['search_wikipedia', 'lookup_wikipedia', 'finish'] required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Next Tool Name:', 'desc': '${next_tool_name}'})\n",
      "    next_tool_args = Field(annotation=dict[str, Any] required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Next Tool Args:', 'desc': '${next_tool_args}'})\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "StringSignature(claim, trajectory -> reasoning, titles\n",
      "    instructions='Find all Wikipedia titles relevant to verifying (or refuting) the claim.'\n",
      "    claim = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Claim:', 'desc': '${claim}'})\n",
      "    trajectory = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Trajectory:', 'desc': '${trajectory}'})\n",
      "    reasoning = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${reasoning}', '__dspy_field_type': 'output'})\n",
      "    titles = Field(annotation=list[str] required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Titles:', 'desc': '${titles}'})\n",
      ")\n",
      "\n",
      "class ReAct(Module):\n",
      "    def __init__(self, signature, tools: list[Callable], max_iters=5):\n",
      "        \"\"\"\n",
      "        `tools` is either a list of functions, callable classes, or `dspy.Tool` instances.\n",
      "        \"\"\"\n",
      "\n",
      "        self.signature = signature = ensure_signature(signature)\n",
      "        self.max_iters = max_iters\n",
      "\n",
      "        tools = [t if isinstance(t, Tool) or hasattr(t, \"input_variable\") else Tool(t) for t in tools]\n",
      "        tools = {tool.name: tool for tool in tools}\n",
      "\n",
      "        inputs = \", \".join([f\"`{k}`\" for k in signature.input_fields.keys()])\n",
      "        outputs = \", \".join([f\"`{k}`\" for k in signature.output_fields.keys()])\n",
      "        instr = [f\"{signature.instructions}\\n\"] if signature.instructions else []\n",
      "\n",
      "        instr.extend(\n",
      "            [\n",
      "                f\"You will be given {inputs} and your goal is to finish with {outputs}.\\n\",\n",
      "                \"To do this, you will interleave Thought, Tool Name, and Tool Args, and receive a resulting Observation.\\n\",\n",
      "                \"Thought can reason about the current situation, and Tool Name can be the following types:\\n\",\n",
      "            ]\n",
      "        )\n",
      "\n",
      "        finish_desc = (\n",
      "            f\"Signals that the final outputs, i.e. {outputs}, are now available and marks the task as complete.\"\n",
      "        )\n",
      "        finish_args = {}  # k: v.annotation for k, v in signature.output_fields.items()}\n",
      "        tools[\"finish\"] = Tool(func=lambda **kwargs: \"Completed.\", name=\"finish\", desc=finish_desc, args=finish_args)\n",
      "\n",
      "        for idx, tool in enumerate(tools.values()):\n",
      "            args = tool.args if hasattr(tool, \"args\") else str({tool.input_variable: str})\n",
      "            desc = (f\", whose description is <desc>{tool.desc}</desc>.\" if tool.desc else \".\").replace(\"\\n\", \"  \")\n",
      "            desc += f\" It takes arguments {args} in JSON format.\"\n",
      "            instr.append(f\"({idx+1}) {tool.name}{desc}\")\n",
      "\n",
      "        react_signature = (\n",
      "            dspy.Signature({**signature.input_fields}, \"\\n\".join(instr))\n",
      "            .append(\"trajectory\", dspy.InputField(), type_=str)\n",
      "            .append(\"next_thought\", dspy.OutputField(), type_=str)\n",
      "            .append(\"next_tool_name\", dspy.OutputField(), type_=Literal[tuple(tools.keys())])\n",
      "            .append(\"next_tool_args\", dspy.OutputField(), type_=dict[str, Any])\n",
      "        )\n",
      "\n",
      "        fallback_signature = dspy.Signature(\n",
      "            {**signature.input_fields, **signature.output_fields}, signature.instructions\n",
      "        ).append(\"trajectory\", dspy.InputField(), type_=str)\n",
      "\n",
      "        self.tools = tools\n",
      "        self.react = dspy.Predict(react_signature)\n",
      "        self.extract = dspy.ChainOfThought(fallback_signature)\n",
      "\n",
      "    def forward(self, **input_args):\n",
      "        def format(trajectory: dict[str, Any], last_iteration: bool):\n",
      "            adapter = dspy.settings.adapter or dspy.ChatAdapter()\n",
      "            trajectory_signature = dspy.Signature(f\"{', '.join(trajectory.keys())} -> x\")\n",
      "            return adapter.format_fields(trajectory_signature, trajectory, role=\"user\")\n",
      "\n",
      "        trajectory = {}\n",
      "        for idx in range(self.max_iters):\n",
      "            pred = self.react(**input_args, trajectory=format(trajectory, last_iteration=(idx == self.max_iters - 1)))\n",
      "\n",
      "            trajectory[f\"thought_{idx}\"] = pred.next_thought\n",
      "            trajectory[f\"tool_name_{idx}\"] = pred.next_tool_name\n",
      "            trajectory[f\"tool_args_{idx}\"] = pred.next_tool_args\n",
      "\n",
      "            try:\n",
      "                trajectory[f\"observation_{idx}\"] = self.tools[pred.next_tool_name](**pred.next_tool_args)\n",
      "            except Exception as e:\n",
      "                trajectory[f\"observation_{idx}\"] = f\"Failed to execute: {e}\"\n",
      "\n",
      "            if pred.next_tool_name == \"finish\":\n",
      "                break\n",
      "\n",
      "        extract = self.extract(**input_args, trajectory=format(trajectory, last_iteration=False))\n",
      "        return dspy.Prediction(trajectory=trajectory, **extract)\n",
      "\n",
      "\n",
      "[[ ## program_description ## ]]\n",
      "This program is designed to solve the task of fact-checking or verifying a given claim using Wikipedia as a source of information. The program uses a pipeline that interacts with language models to generate a sequence of thoughts, tool names, and tool arguments, which are then used to retrieve relevant information from Wikipedia.\n",
      "\n",
      "The program begins by defining a `StringSignature` for the task, which includes the claim to be verified, a trajectory of thoughts and actions, and the output fields for the next thought, the name of the next tool to be used, and the arguments for that tool. The `StringSignature` also includes instructions for the task and descriptions of the available tools.\n",
      "\n",
      "The program then defines a `ReAct` module, which takes in the `StringSignature` and a list of tools as input. The `ReAct` module initializes the tools and creates a new `Signature` object that includes the input fields, instructions, and descriptions of the available tools. It also defines a `finish` tool, which signals that the task is complete and marks the final outputs as available.\n",
      "\n",
      "The `ReAct` module then uses a `Predict` function to generate a sequence of thoughts, tool names, and tool arguments based on the input claim and trajectory. It then executes each tool in the sequence and stores the resulting observations in a trajectory dictionary. If the `finish` tool is used, the task is marked as complete and the final outputs are returned.\n",
      "\n",
      "Overall, this program uses a combination of language models and Wikipedia to verify or refute a given claim. It generates a sequence of thoughts and actions to retrieve relevant information from Wikipedia, and then uses that information to make a determination about the claim.\n",
      "\n",
      "[[ ## module ## ]]\n",
      "Predict(claim, trajectory) -> next_thought, next_tool_name, next_tool_args\n",
      "\n",
      "[[ ## task_demos ## ]]\n",
      "\n",
      "\n",
      "[[ ## basic_instruction ## ]]\n",
      "Find all Wikipedia titles relevant to verifying (or refuting) the claim.\n",
      "\n",
      "You will be given `claim` and your goal is to finish with `titles`.\n",
      "\n",
      "To do this, you will interleave Thought, Tool Name, and Tool Args, and receive a resulting Observation.\n",
      "\n",
      "Thought can reason about the current situation, and Tool Name can be the following types:\n",
      "\n",
      "(1) search_wikipedia, whose description is <desc>Returns top-5 results and then the titles of the top-5 to top-30 results.</desc>. It takes arguments {'query': 'str'} in JSON format.\n",
      "(2) lookup_wikipedia, whose description is <desc>Returns the text of the Wikipedia page, if it exists.</desc>. It takes arguments {'title': 'str'} in JSON format.\n",
      "(3) finish, whose description is <desc>Signals that the final outputs, i.e. `titles`, are now available and marks the task as complete.</desc>. It takes arguments {} in JSON format.\n",
      "\n",
      "[[ ## tip ## ]]\n",
      "Don't be afraid to be creative when creating the new instruction!\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## proposed_instruction ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## proposed_instruction ## ]]\n",
      "To verify the given claim, identify the key entities or events mentioned within it. Then, generate a list of potential Wikipedia search queries that could yield relevant information about these entities or events. Utilize the `search_wikipedia` tool to execute these queries and retrieve the top-5 results. Extract the titles of the top-5 to top-30 results from these search results. If necessary, use the `lookup_wikipedia` tool to gather more detailed information from specific Wikipedia pages. Once you have gathered sufficient evidence, use the `finish` tool to signal that the task is complete and provide the final list of relevant Wikipedia titles.\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "PROPOSED INSTRUCTION: To verify the given claim, identify the key entities or events mentioned within it. Then, generate a list of potential Wikipedia search queries that could yield relevant information about these entities or events. Utilize the `search_wikipedia` tool to execute these queries and retrieve the top-5 results. Extract the titles of the top-5 to top-30 results from these search results. If necessary, use the `lookup_wikipedia` tool to gather more detailed information from specific Wikipedia pages. Once you have gathered sufficient evidence, use the `finish` tool to signal that the task is complete and provide the final list of relevant Wikipedia titles.\n",
      "Using a randomly generated configuration for our grounded proposer.\n",
      "Selected tip: none\n",
      "PROGRAM DESCRIPTION: This program is designed to solve the task of fact-checking or verifying a given claim using Wikipedia as a source of information. The program uses a pipeline that interacts with language models to generate a sequence of thoughts, tool names, and tool arguments, which are then used to retrieve relevant information from Wikipedia.\n",
      "\n",
      "The program begins by defining a `StringSignature` for the task, which includes the claim to be verified, a trajectory of thoughts and actions, and the output fields for the next thought, the name of the next tool to be used, and the arguments for that tool. The `StringSignature` also includes instructions for the task and descriptions of the available tools.\n",
      "\n",
      "The program then defines a `ReAct` module, which takes in the `StringSignature` and a list of tools as input. The `ReAct` module initializes the tools and creates a new `Signature` object that includes the input fields, instructions, and descriptions of the available tools. It also defines a `finish` tool, which signals that the task is complete and marks the final outputs as available.\n",
      "\n",
      "The `ReAct` module then uses a `Predict` function to generate a sequence of thoughts, tool names, and tool arguments based on the input claim and trajectory. It then executes each tool in the sequence and stores the resulting observations in a trajectory dictionary. If the `finish` tool is used, the task is marked as complete and the final outputs are returned.\n",
      "\n",
      "Overall, this program uses a combination of language models and Wikipedia to verify or refute a given claim. It generates a sequence of thoughts and actions to retrieve relevant information from Wikipedia, and then uses that information to make a determination about the claim.\n",
      "task_demos \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-01-07T18:51:50.805555]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `dataset_description` (str): A description of the dataset that we are using.\n",
      "2. `program_code` (str): Language model program designed to solve a particular task.\n",
      "3. `program_description` (str): Summary of the task the program is designed to solve, and how it goes about solving it.\n",
      "4. `module` (str): The module to create an instruction for.\n",
      "5. `task_demos` (str): Example inputs/outputs of our module.\n",
      "6. `basic_instruction` (str): Basic instruction.\n",
      "\n",
      "Your output fields are:\n",
      "1. `proposed_instruction` (str): Propose an instruction that will be used to prompt a Language Model to perform this task.\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## dataset_description ## ]]\n",
      "{dataset_description}\n",
      "\n",
      "[[ ## program_code ## ]]\n",
      "{program_code}\n",
      "\n",
      "[[ ## program_description ## ]]\n",
      "{program_description}\n",
      "\n",
      "[[ ## module ## ]]\n",
      "{module}\n",
      "\n",
      "[[ ## task_demos ## ]]\n",
      "{task_demos}\n",
      "\n",
      "[[ ## basic_instruction ## ]]\n",
      "{basic_instruction}\n",
      "\n",
      "[[ ## proposed_instruction ## ]]\n",
      "{proposed_instruction}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        Use the information below to learn about a task that we are trying to solve using calls to an LM, then generate a new instruction that will be used to prompt a Language Model to better solve the task.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## dataset_description ## ]]\n",
      "The dataset comprises concise claims connecting topics or individuals to specific details or events, indicating potential use for fact-checking or knowledge validation. Each claim is associated with titles that may act as evidence or context, and the dataset covers a wide range of domains including film, railway routes, and martial arts. The brevity and clarity of the claims suggest their use in tasks requiring direct factual statements.\n",
      "\n",
      "[[ ## program_code ## ]]\n",
      "StringSignature(claim, trajectory -> next_thought, next_tool_name, next_tool_args\n",
      "    instructions=\"Find all Wikipedia titles relevant to verifying (or refuting) the claim.\\n\\nYou will be given `claim` and your goal is to finish with `titles`.\\n\\nTo do this, you will interleave Thought, Tool Name, and Tool Args, and receive a resulting Observation.\\n\\nThought can reason about the current situation, and Tool Name can be the following types:\\n\\n(1) search_wikipedia, whose description is <desc>Returns top-5 results and then the titles of the top-5 to top-30 results.</desc>. It takes arguments {'query': 'str'} in JSON format.\\n(2) lookup_wikipedia, whose description is <desc>Returns the text of the Wikipedia page, if it exists.</desc>. It takes arguments {'title': 'str'} in JSON format.\\n(3) finish, whose description is <desc>Signals that the final outputs, i.e. `titles`, are now available and marks the task as complete.</desc>. It takes arguments {} in JSON format.\"\n",
      "    claim = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Claim:', 'desc': '${claim}'})\n",
      "    trajectory = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Trajectory:', 'desc': '${trajectory}'})\n",
      "    next_thought = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Next Thought:', 'desc': '${next_thought}'})\n",
      "    next_tool_name = Field(annotation=Literal['search_wikipedia', 'lookup_wikipedia', 'finish'] required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Next Tool Name:', 'desc': '${next_tool_name}'})\n",
      "    next_tool_args = Field(annotation=dict[str, Any] required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Next Tool Args:', 'desc': '${next_tool_args}'})\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "StringSignature(claim, trajectory -> reasoning, titles\n",
      "    instructions='Find all Wikipedia titles relevant to verifying (or refuting) the claim.'\n",
      "    claim = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Claim:', 'desc': '${claim}'})\n",
      "    trajectory = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Trajectory:', 'desc': '${trajectory}'})\n",
      "    reasoning = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${reasoning}', '__dspy_field_type': 'output'})\n",
      "    titles = Field(annotation=list[str] required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Titles:', 'desc': '${titles}'})\n",
      ")\n",
      "\n",
      "class ReAct(Module):\n",
      "    def __init__(self, signature, tools: list[Callable], max_iters=5):\n",
      "        \"\"\"\n",
      "        `tools` is either a list of functions, callable classes, or `dspy.Tool` instances.\n",
      "        \"\"\"\n",
      "\n",
      "        self.signature = signature = ensure_signature(signature)\n",
      "        self.max_iters = max_iters\n",
      "\n",
      "        tools = [t if isinstance(t, Tool) or hasattr(t, \"input_variable\") else Tool(t) for t in tools]\n",
      "        tools = {tool.name: tool for tool in tools}\n",
      "\n",
      "        inputs = \", \".join([f\"`{k}`\" for k in signature.input_fields.keys()])\n",
      "        outputs = \", \".join([f\"`{k}`\" for k in signature.output_fields.keys()])\n",
      "        instr = [f\"{signature.instructions}\\n\"] if signature.instructions else []\n",
      "\n",
      "        instr.extend(\n",
      "            [\n",
      "                f\"You will be given {inputs} and your goal is to finish with {outputs}.\\n\",\n",
      "                \"To do this, you will interleave Thought, Tool Name, and Tool Args, and receive a resulting Observation.\\n\",\n",
      "                \"Thought can reason about the current situation, and Tool Name can be the following types:\\n\",\n",
      "            ]\n",
      "        )\n",
      "\n",
      "        finish_desc = (\n",
      "            f\"Signals that the final outputs, i.e. {outputs}, are now available and marks the task as complete.\"\n",
      "        )\n",
      "        finish_args = {}  # k: v.annotation for k, v in signature.output_fields.items()}\n",
      "        tools[\"finish\"] = Tool(func=lambda **kwargs: \"Completed.\", name=\"finish\", desc=finish_desc, args=finish_args)\n",
      "\n",
      "        for idx, tool in enumerate(tools.values()):\n",
      "            args = tool.args if hasattr(tool, \"args\") else str({tool.input_variable: str})\n",
      "            desc = (f\", whose description is <desc>{tool.desc}</desc>.\" if tool.desc else \".\").replace(\"\\n\", \"  \")\n",
      "            desc += f\" It takes arguments {args} in JSON format.\"\n",
      "            instr.append(f\"({idx+1}) {tool.name}{desc}\")\n",
      "\n",
      "        react_signature = (\n",
      "            dspy.Signature({**signature.input_fields}, \"\\n\".join(instr))\n",
      "            .append(\"trajectory\", dspy.InputField(), type_=str)\n",
      "            .append(\"next_thought\", dspy.OutputField(), type_=str)\n",
      "            .append(\"next_tool_name\", dspy.OutputField(), type_=Literal[tuple(tools.keys())])\n",
      "            .append(\"next_tool_args\", dspy.OutputField(), type_=dict[str, Any])\n",
      "        )\n",
      "\n",
      "        fallback_signature = dspy.Signature(\n",
      "            {**signature.input_fields, **signature.output_fields}, signature.instructions\n",
      "        ).append(\"trajectory\", dspy.InputField(), type_=str)\n",
      "\n",
      "        self.tools = tools\n",
      "        self.react = dspy.Predict(react_signature)\n",
      "        self.extract = dspy.ChainOfThought(fallback_signature)\n",
      "\n",
      "    def forward(self, **input_args):\n",
      "        def format(trajectory: dict[str, Any], last_iteration: bool):\n",
      "            adapter = dspy.settings.adapter or dspy.ChatAdapter()\n",
      "            trajectory_signature = dspy.Signature(f\"{', '.join(trajectory.keys())} -> x\")\n",
      "            return adapter.format_fields(trajectory_signature, trajectory, role=\"user\")\n",
      "\n",
      "        trajectory = {}\n",
      "        for idx in range(self.max_iters):\n",
      "            pred = self.react(**input_args, trajectory=format(trajectory, last_iteration=(idx == self.max_iters - 1)))\n",
      "\n",
      "            trajectory[f\"thought_{idx}\"] = pred.next_thought\n",
      "            trajectory[f\"tool_name_{idx}\"] = pred.next_tool_name\n",
      "            trajectory[f\"tool_args_{idx}\"] = pred.next_tool_args\n",
      "\n",
      "            try:\n",
      "                trajectory[f\"observation_{idx}\"] = self.tools[pred.next_tool_name](**pred.next_tool_args)\n",
      "            except Exception as e:\n",
      "                trajectory[f\"observation_{idx}\"] = f\"Failed to execute: {e}\"\n",
      "\n",
      "            if pred.next_tool_name == \"finish\":\n",
      "                break\n",
      "\n",
      "        extract = self.extract(**input_args, trajectory=format(trajectory, last_iteration=False))\n",
      "        return dspy.Prediction(trajectory=trajectory, **extract)\n",
      "\n",
      "\n",
      "[[ ## program_description ## ]]\n",
      "This program is designed to solve the task of fact-checking or verifying a given claim using Wikipedia as a source of information. The program uses a pipeline that interacts with language models to generate a sequence of thoughts, tool names, and tool arguments, which are then used to retrieve relevant information from Wikipedia.\n",
      "\n",
      "The program begins by defining a `StringSignature` for the task, which includes the claim to be verified, a trajectory of thoughts and actions, and the output fields for the next thought, the name of the next tool to be used, and the arguments for that tool. The `StringSignature` also includes instructions for the task and descriptions of the available tools.\n",
      "\n",
      "The program then defines a `ReAct` module, which takes in the `StringSignature` and a list of tools as input. The `ReAct` module initializes the tools and creates a new `Signature` object that includes the input fields, instructions, and descriptions of the available tools. It also defines a `finish` tool, which signals that the task is complete and marks the final outputs as available.\n",
      "\n",
      "The `ReAct` module then uses a `Predict` function to generate a sequence of thoughts, tool names, and tool arguments based on the input claim and trajectory. It then executes each tool in the sequence and stores the resulting observations in a trajectory dictionary. If the `finish` tool is used, the task is marked as complete and the final outputs are returned.\n",
      "\n",
      "Overall, this program uses a combination of language models and Wikipedia to verify or refute a given claim. It generates a sequence of thoughts and actions to retrieve relevant information from Wikipedia, and then uses that information to make a determination about the claim.\n",
      "\n",
      "[[ ## module ## ]]\n",
      "Predict(claim, trajectory) -> next_thought, next_tool_name, next_tool_args\n",
      "\n",
      "[[ ## task_demos ## ]]\n",
      "\n",
      "\n",
      "[[ ## basic_instruction ## ]]\n",
      "Find all Wikipedia titles relevant to verifying (or refuting) the claim.\n",
      "\n",
      "You will be given `claim` and your goal is to finish with `titles`.\n",
      "\n",
      "To do this, you will interleave Thought, Tool Name, and Tool Args, and receive a resulting Observation.\n",
      "\n",
      "Thought can reason about the current situation, and Tool Name can be the following types:\n",
      "\n",
      "(1) search_wikipedia, whose description is <desc>Returns top-5 results and then the titles of the top-5 to top-30 results.</desc>. It takes arguments {'query': 'str'} in JSON format.\n",
      "(2) lookup_wikipedia, whose description is <desc>Returns the text of the Wikipedia page, if it exists.</desc>. It takes arguments {'title': 'str'} in JSON format.\n",
      "(3) finish, whose description is <desc>Signals that the final outputs, i.e. `titles`, are now available and marks the task as complete.</desc>. It takes arguments {} in JSON format.\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## proposed_instruction ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## proposed_instruction ## ]]\n",
      "Given a claim, your task is to identify relevant Wikipedia titles that can be used to verify or refute the claim. You will do this by generating a sequence of thoughts, tool names, and tool arguments, and then executing the corresponding tools to retrieve information from Wikipedia. Your final output should be a list of Wikipedia titles that are relevant to the claim.\n",
      "\n",
      "To begin, analyze the claim and generate a thought that describes the initial situation and your plan for identifying relevant titles. Then, choose a tool and provide the necessary arguments for executing that tool. Repeat this process until you have identified all relevant titles, and then use the `finish` tool to signal that the task is complete.\n",
      "\n",
      "Remember to follow the instructions carefully and use the available tools appropriately. Your output should include the fields `next_thought`, `next_tool_name`, and `next_tool_args`.\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "PROPOSED INSTRUCTION: Given a claim, your task is to identify relevant Wikipedia titles that can be used to verify or refute the claim. You will do this by generating a sequence of thoughts, tool names, and tool arguments, and then executing the corresponding tools to retrieve information from Wikipedia. Your final output should be a list of Wikipedia titles that are relevant to the claim.\n",
      "\n",
      "To begin, analyze the claim and generate a thought that describes the initial situation and your plan for identifying relevant titles. Then, choose a tool and provide the necessary arguments for executing that tool. Repeat this process until you have identified all relevant titles, and then use the `finish` tool to signal that the task is complete.\n",
      "\n",
      "Remember to follow the instructions carefully and use the available tools appropriately. Your output should include the fields `next_thought`, `next_tool_name`, and `next_tool_args`.\n",
      "Using a randomly generated configuration for our grounded proposer.\n",
      "Selected tip: none\n",
      "PROGRAM DESCRIPTION: This program is designed to solve the task of fact-checking or verifying a given claim using Wikipedia as a source of information. The program uses a pipeline that interacts with language models to generate a sequence of thoughts, tool names, and tool arguments, which are then used to retrieve relevant information from Wikipedia.\n",
      "\n",
      "The program begins by defining a `StringSignature` for the task, which includes the claim to be verified, a trajectory of thoughts and actions, and the output fields for the next thought, the name of the next tool to be used, and the arguments for that tool. The `StringSignature` also includes instructions for the task and descriptions of the available tools.\n",
      "\n",
      "The program then defines a `ReAct` module, which takes in the `StringSignature` and a list of tools as input. The `ReAct` module initializes the tools and creates a new `Signature` object that includes the input fields, instructions, and descriptions of the available tools. It also defines a `finish` tool, which signals that the task is complete and marks the final outputs as available.\n",
      "\n",
      "The `ReAct` module then uses a `Predict` function to generate a sequence of thoughts, tool names, and tool arguments based on the input claim and trajectory. It then executes each tool in the sequence and stores the resulting observations in a trajectory dictionary. If the `finish` tool is used, the task is marked as complete and the final outputs are returned.\n",
      "\n",
      "Overall, this program uses a combination of language models and Wikipedia to verify or refute a given claim. It generates a sequence of thoughts and actions to retrieve relevant information from Wikipedia, and then uses that information to make a determination about the claim.\n",
      "task_demos \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-01-07T18:51:59.594437]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `dataset_description` (str): A description of the dataset that we are using.\n",
      "2. `program_code` (str): Language model program designed to solve a particular task.\n",
      "3. `program_description` (str): Summary of the task the program is designed to solve, and how it goes about solving it.\n",
      "4. `module` (str): The module to create an instruction for.\n",
      "5. `task_demos` (str): Example inputs/outputs of our module.\n",
      "6. `basic_instruction` (str): Basic instruction.\n",
      "\n",
      "Your output fields are:\n",
      "1. `proposed_instruction` (str): Propose an instruction that will be used to prompt a Language Model to perform this task.\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## dataset_description ## ]]\n",
      "{dataset_description}\n",
      "\n",
      "[[ ## program_code ## ]]\n",
      "{program_code}\n",
      "\n",
      "[[ ## program_description ## ]]\n",
      "{program_description}\n",
      "\n",
      "[[ ## module ## ]]\n",
      "{module}\n",
      "\n",
      "[[ ## task_demos ## ]]\n",
      "{task_demos}\n",
      "\n",
      "[[ ## basic_instruction ## ]]\n",
      "{basic_instruction}\n",
      "\n",
      "[[ ## proposed_instruction ## ]]\n",
      "{proposed_instruction}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        Use the information below to learn about a task that we are trying to solve using calls to an LM, then generate a new instruction that will be used to prompt a Language Model to better solve the task.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## dataset_description ## ]]\n",
      "The dataset comprises concise claims connecting topics or individuals to specific details or events, indicating potential use for fact-checking or knowledge validation. Each claim is associated with titles that may act as evidence or context, and the dataset covers a wide range of domains including film, railway routes, and martial arts. The brevity and clarity of the claims suggest their use in tasks requiring direct factual statements.\n",
      "\n",
      "[[ ## program_code ## ]]\n",
      "StringSignature(claim, trajectory -> next_thought, next_tool_name, next_tool_args\n",
      "    instructions=\"Find all Wikipedia titles relevant to verifying (or refuting) the claim.\\n\\nYou will be given `claim` and your goal is to finish with `titles`.\\n\\nTo do this, you will interleave Thought, Tool Name, and Tool Args, and receive a resulting Observation.\\n\\nThought can reason about the current situation, and Tool Name can be the following types:\\n\\n(1) search_wikipedia, whose description is <desc>Returns top-5 results and then the titles of the top-5 to top-30 results.</desc>. It takes arguments {'query': 'str'} in JSON format.\\n(2) lookup_wikipedia, whose description is <desc>Returns the text of the Wikipedia page, if it exists.</desc>. It takes arguments {'title': 'str'} in JSON format.\\n(3) finish, whose description is <desc>Signals that the final outputs, i.e. `titles`, are now available and marks the task as complete.</desc>. It takes arguments {} in JSON format.\"\n",
      "    claim = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Claim:', 'desc': '${claim}'})\n",
      "    trajectory = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Trajectory:', 'desc': '${trajectory}'})\n",
      "    next_thought = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Next Thought:', 'desc': '${next_thought}'})\n",
      "    next_tool_name = Field(annotation=Literal['search_wikipedia', 'lookup_wikipedia', 'finish'] required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Next Tool Name:', 'desc': '${next_tool_name}'})\n",
      "    next_tool_args = Field(annotation=dict[str, Any] required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Next Tool Args:', 'desc': '${next_tool_args}'})\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "StringSignature(claim, trajectory -> reasoning, titles\n",
      "    instructions='Find all Wikipedia titles relevant to verifying (or refuting) the claim.'\n",
      "    claim = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Claim:', 'desc': '${claim}'})\n",
      "    trajectory = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Trajectory:', 'desc': '${trajectory}'})\n",
      "    reasoning = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${reasoning}', '__dspy_field_type': 'output'})\n",
      "    titles = Field(annotation=list[str] required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Titles:', 'desc': '${titles}'})\n",
      ")\n",
      "\n",
      "class ReAct(Module):\n",
      "    def __init__(self, signature, tools: list[Callable], max_iters=5):\n",
      "        \"\"\"\n",
      "        `tools` is either a list of functions, callable classes, or `dspy.Tool` instances.\n",
      "        \"\"\"\n",
      "\n",
      "        self.signature = signature = ensure_signature(signature)\n",
      "        self.max_iters = max_iters\n",
      "\n",
      "        tools = [t if isinstance(t, Tool) or hasattr(t, \"input_variable\") else Tool(t) for t in tools]\n",
      "        tools = {tool.name: tool for tool in tools}\n",
      "\n",
      "        inputs = \", \".join([f\"`{k}`\" for k in signature.input_fields.keys()])\n",
      "        outputs = \", \".join([f\"`{k}`\" for k in signature.output_fields.keys()])\n",
      "        instr = [f\"{signature.instructions}\\n\"] if signature.instructions else []\n",
      "\n",
      "        instr.extend(\n",
      "            [\n",
      "                f\"You will be given {inputs} and your goal is to finish with {outputs}.\\n\",\n",
      "                \"To do this, you will interleave Thought, Tool Name, and Tool Args, and receive a resulting Observation.\\n\",\n",
      "                \"Thought can reason about the current situation, and Tool Name can be the following types:\\n\",\n",
      "            ]\n",
      "        )\n",
      "\n",
      "        finish_desc = (\n",
      "            f\"Signals that the final outputs, i.e. {outputs}, are now available and marks the task as complete.\"\n",
      "        )\n",
      "        finish_args = {}  # k: v.annotation for k, v in signature.output_fields.items()}\n",
      "        tools[\"finish\"] = Tool(func=lambda **kwargs: \"Completed.\", name=\"finish\", desc=finish_desc, args=finish_args)\n",
      "\n",
      "        for idx, tool in enumerate(tools.values()):\n",
      "            args = tool.args if hasattr(tool, \"args\") else str({tool.input_variable: str})\n",
      "            desc = (f\", whose description is <desc>{tool.desc}</desc>.\" if tool.desc else \".\").replace(\"\\n\", \"  \")\n",
      "            desc += f\" It takes arguments {args} in JSON format.\"\n",
      "            instr.append(f\"({idx+1}) {tool.name}{desc}\")\n",
      "\n",
      "        react_signature = (\n",
      "            dspy.Signature({**signature.input_fields}, \"\\n\".join(instr))\n",
      "            .append(\"trajectory\", dspy.InputField(), type_=str)\n",
      "            .append(\"next_thought\", dspy.OutputField(), type_=str)\n",
      "            .append(\"next_tool_name\", dspy.OutputField(), type_=Literal[tuple(tools.keys())])\n",
      "            .append(\"next_tool_args\", dspy.OutputField(), type_=dict[str, Any])\n",
      "        )\n",
      "\n",
      "        fallback_signature = dspy.Signature(\n",
      "            {**signature.input_fields, **signature.output_fields}, signature.instructions\n",
      "        ).append(\"trajectory\", dspy.InputField(), type_=str)\n",
      "\n",
      "        self.tools = tools\n",
      "        self.react = dspy.Predict(react_signature)\n",
      "        self.extract = dspy.ChainOfThought(fallback_signature)\n",
      "\n",
      "    def forward(self, **input_args):\n",
      "        def format(trajectory: dict[str, Any], last_iteration: bool):\n",
      "            adapter = dspy.settings.adapter or dspy.ChatAdapter()\n",
      "            trajectory_signature = dspy.Signature(f\"{', '.join(trajectory.keys())} -> x\")\n",
      "            return adapter.format_fields(trajectory_signature, trajectory, role=\"user\")\n",
      "\n",
      "        trajectory = {}\n",
      "        for idx in range(self.max_iters):\n",
      "            pred = self.react(**input_args, trajectory=format(trajectory, last_iteration=(idx == self.max_iters - 1)))\n",
      "\n",
      "            trajectory[f\"thought_{idx}\"] = pred.next_thought\n",
      "            trajectory[f\"tool_name_{idx}\"] = pred.next_tool_name\n",
      "            trajectory[f\"tool_args_{idx}\"] = pred.next_tool_args\n",
      "\n",
      "            try:\n",
      "                trajectory[f\"observation_{idx}\"] = self.tools[pred.next_tool_name](**pred.next_tool_args)\n",
      "            except Exception as e:\n",
      "                trajectory[f\"observation_{idx}\"] = f\"Failed to execute: {e}\"\n",
      "\n",
      "            if pred.next_tool_name == \"finish\":\n",
      "                break\n",
      "\n",
      "        extract = self.extract(**input_args, trajectory=format(trajectory, last_iteration=False))\n",
      "        return dspy.Prediction(trajectory=trajectory, **extract)\n",
      "\n",
      "\n",
      "[[ ## program_description ## ]]\n",
      "This program is designed to solve the task of fact-checking or verifying a given claim using Wikipedia as a source of information. The program uses a pipeline that interacts with language models to generate a sequence of thoughts, tool names, and tool arguments, which are then used to retrieve relevant information from Wikipedia.\n",
      "\n",
      "The program begins by defining a `StringSignature` for the task, which includes the claim to be verified, a trajectory of thoughts and actions, and the output fields for the next thought, the name of the next tool to be used, and the arguments for that tool. The `StringSignature` also includes instructions for the task and descriptions of the available tools.\n",
      "\n",
      "The program then defines a `ReAct` module, which takes in the `StringSignature` and a list of tools as input. The `ReAct` module initializes the tools and creates a new `Signature` object that includes the input fields, instructions, and descriptions of the available tools. It also defines a `finish` tool, which signals that the task is complete and marks the final outputs as available.\n",
      "\n",
      "The `ReAct` module then uses a `Predict` function to generate a sequence of thoughts, tool names, and tool arguments based on the input claim and trajectory. It then executes each tool in the sequence and stores the resulting observations in a trajectory dictionary. If the `finish` tool is used, the task is marked as complete and the final outputs are returned.\n",
      "\n",
      "Overall, this program uses a combination of language models and Wikipedia to verify or refute a given claim. It generates a sequence of thoughts and actions to retrieve relevant information from Wikipedia, and then uses that information to make a determination about the claim.\n",
      "\n",
      "[[ ## module ## ]]\n",
      "Predict(claim, trajectory) -> reasoning, titles\n",
      "\n",
      "[[ ## task_demos ## ]]\n",
      "\n",
      "\n",
      "[[ ## basic_instruction ## ]]\n",
      "Find all Wikipedia titles relevant to verifying (or refuting) the claim.\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## proposed_instruction ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## proposed_instruction ## ]]\n",
      "Based on the given claim, generate a sequence of thoughts, tool names, and tool arguments to find all relevant Wikipedia titles for verifying or refuting the claim. Ensure that the final output includes the reasoning behind the sequence of thoughts and actions, as well as the list of Wikipedia titles.\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "PROPOSED INSTRUCTION: Based on the given claim, generate a sequence of thoughts, tool names, and tool arguments to find all relevant Wikipedia titles for verifying or refuting the claim. Ensure that the final output includes the reasoning behind the sequence of thoughts and actions, as well as the list of Wikipedia titles.\n",
      "Using a randomly generated configuration for our grounded proposer.\n",
      "Selected tip: creative\n",
      "PROGRAM DESCRIPTION: This program is designed to solve the task of fact-checking or verifying a given claim using Wikipedia as a source of information. The program uses a pipeline that interacts with language models to generate a sequence of thoughts, tool names, and tool arguments, which are then used to retrieve relevant information from Wikipedia.\n",
      "\n",
      "The program begins by defining a `StringSignature` for the task, which includes the claim to be verified, a trajectory of thoughts and actions, and the output fields for the next thought, the name of the next tool to be used, and the arguments for that tool. The `StringSignature` also includes instructions for the task and descriptions of the available tools.\n",
      "\n",
      "The program then defines a `ReAct` module, which takes in the `StringSignature` and a list of tools as input. The `ReAct` module initializes the tools and creates a new `Signature` object that includes the input fields, instructions, and descriptions of the available tools. It also defines a `finish` tool, which signals that the task is complete and marks the final outputs as available.\n",
      "\n",
      "The `ReAct` module then uses a `Predict` function to generate a sequence of thoughts, tool names, and tool arguments based on the input claim and trajectory. It then executes each tool in the sequence and stores the resulting observations in a trajectory dictionary. If the `finish` tool is used, the task is marked as complete and the final outputs are returned.\n",
      "\n",
      "Overall, this program uses a combination of language models and Wikipedia to verify or refute a given claim. It generates a sequence of thoughts and actions to retrieve relevant information from Wikipedia, and then uses that information to make a determination about the claim.\n",
      "task_demos \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-01-07T18:52:02.277825]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `dataset_description` (str): A description of the dataset that we are using.\n",
      "2. `program_code` (str): Language model program designed to solve a particular task.\n",
      "3. `program_description` (str): Summary of the task the program is designed to solve, and how it goes about solving it.\n",
      "4. `module` (str): The module to create an instruction for.\n",
      "5. `task_demos` (str): Example inputs/outputs of our module.\n",
      "6. `basic_instruction` (str): Basic instruction.\n",
      "7. `tip` (str): A suggestion for how to go about generating the new instruction.\n",
      "\n",
      "Your output fields are:\n",
      "1. `proposed_instruction` (str): Propose an instruction that will be used to prompt a Language Model to perform this task.\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## dataset_description ## ]]\n",
      "{dataset_description}\n",
      "\n",
      "[[ ## program_code ## ]]\n",
      "{program_code}\n",
      "\n",
      "[[ ## program_description ## ]]\n",
      "{program_description}\n",
      "\n",
      "[[ ## module ## ]]\n",
      "{module}\n",
      "\n",
      "[[ ## task_demos ## ]]\n",
      "{task_demos}\n",
      "\n",
      "[[ ## basic_instruction ## ]]\n",
      "{basic_instruction}\n",
      "\n",
      "[[ ## tip ## ]]\n",
      "{tip}\n",
      "\n",
      "[[ ## proposed_instruction ## ]]\n",
      "{proposed_instruction}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        Use the information below to learn about a task that we are trying to solve using calls to an LM, then generate a new instruction that will be used to prompt a Language Model to better solve the task.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## dataset_description ## ]]\n",
      "The dataset comprises concise claims connecting topics or individuals to specific details or events, indicating potential use for fact-checking or knowledge validation. Each claim is associated with titles that may act as evidence or context, and the dataset covers a wide range of domains including film, railway routes, and martial arts. The brevity and clarity of the claims suggest their use in tasks requiring direct factual statements.\n",
      "\n",
      "[[ ## program_code ## ]]\n",
      "StringSignature(claim, trajectory -> next_thought, next_tool_name, next_tool_args\n",
      "    instructions=\"Find all Wikipedia titles relevant to verifying (or refuting) the claim.\\n\\nYou will be given `claim` and your goal is to finish with `titles`.\\n\\nTo do this, you will interleave Thought, Tool Name, and Tool Args, and receive a resulting Observation.\\n\\nThought can reason about the current situation, and Tool Name can be the following types:\\n\\n(1) search_wikipedia, whose description is <desc>Returns top-5 results and then the titles of the top-5 to top-30 results.</desc>. It takes arguments {'query': 'str'} in JSON format.\\n(2) lookup_wikipedia, whose description is <desc>Returns the text of the Wikipedia page, if it exists.</desc>. It takes arguments {'title': 'str'} in JSON format.\\n(3) finish, whose description is <desc>Signals that the final outputs, i.e. `titles`, are now available and marks the task as complete.</desc>. It takes arguments {} in JSON format.\"\n",
      "    claim = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Claim:', 'desc': '${claim}'})\n",
      "    trajectory = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Trajectory:', 'desc': '${trajectory}'})\n",
      "    next_thought = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Next Thought:', 'desc': '${next_thought}'})\n",
      "    next_tool_name = Field(annotation=Literal['search_wikipedia', 'lookup_wikipedia', 'finish'] required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Next Tool Name:', 'desc': '${next_tool_name}'})\n",
      "    next_tool_args = Field(annotation=dict[str, Any] required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Next Tool Args:', 'desc': '${next_tool_args}'})\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "StringSignature(claim, trajectory -> reasoning, titles\n",
      "    instructions='Find all Wikipedia titles relevant to verifying (or refuting) the claim.'\n",
      "    claim = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Claim:', 'desc': '${claim}'})\n",
      "    trajectory = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Trajectory:', 'desc': '${trajectory}'})\n",
      "    reasoning = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${reasoning}', '__dspy_field_type': 'output'})\n",
      "    titles = Field(annotation=list[str] required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Titles:', 'desc': '${titles}'})\n",
      ")\n",
      "\n",
      "class ReAct(Module):\n",
      "    def __init__(self, signature, tools: list[Callable], max_iters=5):\n",
      "        \"\"\"\n",
      "        `tools` is either a list of functions, callable classes, or `dspy.Tool` instances.\n",
      "        \"\"\"\n",
      "\n",
      "        self.signature = signature = ensure_signature(signature)\n",
      "        self.max_iters = max_iters\n",
      "\n",
      "        tools = [t if isinstance(t, Tool) or hasattr(t, \"input_variable\") else Tool(t) for t in tools]\n",
      "        tools = {tool.name: tool for tool in tools}\n",
      "\n",
      "        inputs = \", \".join([f\"`{k}`\" for k in signature.input_fields.keys()])\n",
      "        outputs = \", \".join([f\"`{k}`\" for k in signature.output_fields.keys()])\n",
      "        instr = [f\"{signature.instructions}\\n\"] if signature.instructions else []\n",
      "\n",
      "        instr.extend(\n",
      "            [\n",
      "                f\"You will be given {inputs} and your goal is to finish with {outputs}.\\n\",\n",
      "                \"To do this, you will interleave Thought, Tool Name, and Tool Args, and receive a resulting Observation.\\n\",\n",
      "                \"Thought can reason about the current situation, and Tool Name can be the following types:\\n\",\n",
      "            ]\n",
      "        )\n",
      "\n",
      "        finish_desc = (\n",
      "            f\"Signals that the final outputs, i.e. {outputs}, are now available and marks the task as complete.\"\n",
      "        )\n",
      "        finish_args = {}  # k: v.annotation for k, v in signature.output_fields.items()}\n",
      "        tools[\"finish\"] = Tool(func=lambda **kwargs: \"Completed.\", name=\"finish\", desc=finish_desc, args=finish_args)\n",
      "\n",
      "        for idx, tool in enumerate(tools.values()):\n",
      "            args = tool.args if hasattr(tool, \"args\") else str({tool.input_variable: str})\n",
      "            desc = (f\", whose description is <desc>{tool.desc}</desc>.\" if tool.desc else \".\").replace(\"\\n\", \"  \")\n",
      "            desc += f\" It takes arguments {args} in JSON format.\"\n",
      "            instr.append(f\"({idx+1}) {tool.name}{desc}\")\n",
      "\n",
      "        react_signature = (\n",
      "            dspy.Signature({**signature.input_fields}, \"\\n\".join(instr))\n",
      "            .append(\"trajectory\", dspy.InputField(), type_=str)\n",
      "            .append(\"next_thought\", dspy.OutputField(), type_=str)\n",
      "            .append(\"next_tool_name\", dspy.OutputField(), type_=Literal[tuple(tools.keys())])\n",
      "            .append(\"next_tool_args\", dspy.OutputField(), type_=dict[str, Any])\n",
      "        )\n",
      "\n",
      "        fallback_signature = dspy.Signature(\n",
      "            {**signature.input_fields, **signature.output_fields}, signature.instructions\n",
      "        ).append(\"trajectory\", dspy.InputField(), type_=str)\n",
      "\n",
      "        self.tools = tools\n",
      "        self.react = dspy.Predict(react_signature)\n",
      "        self.extract = dspy.ChainOfThought(fallback_signature)\n",
      "\n",
      "    def forward(self, **input_args):\n",
      "        def format(trajectory: dict[str, Any], last_iteration: bool):\n",
      "            adapter = dspy.settings.adapter or dspy.ChatAdapter()\n",
      "            trajectory_signature = dspy.Signature(f\"{', '.join(trajectory.keys())} -> x\")\n",
      "            return adapter.format_fields(trajectory_signature, trajectory, role=\"user\")\n",
      "\n",
      "        trajectory = {}\n",
      "        for idx in range(self.max_iters):\n",
      "            pred = self.react(**input_args, trajectory=format(trajectory, last_iteration=(idx == self.max_iters - 1)))\n",
      "\n",
      "            trajectory[f\"thought_{idx}\"] = pred.next_thought\n",
      "            trajectory[f\"tool_name_{idx}\"] = pred.next_tool_name\n",
      "            trajectory[f\"tool_args_{idx}\"] = pred.next_tool_args\n",
      "\n",
      "            try:\n",
      "                trajectory[f\"observation_{idx}\"] = self.tools[pred.next_tool_name](**pred.next_tool_args)\n",
      "            except Exception as e:\n",
      "                trajectory[f\"observation_{idx}\"] = f\"Failed to execute: {e}\"\n",
      "\n",
      "            if pred.next_tool_name == \"finish\":\n",
      "                break\n",
      "\n",
      "        extract = self.extract(**input_args, trajectory=format(trajectory, last_iteration=False))\n",
      "        return dspy.Prediction(trajectory=trajectory, **extract)\n",
      "\n",
      "\n",
      "[[ ## program_description ## ]]\n",
      "This program is designed to solve the task of fact-checking or verifying a given claim using Wikipedia as a source of information. The program uses a pipeline that interacts with language models to generate a sequence of thoughts, tool names, and tool arguments, which are then used to retrieve relevant information from Wikipedia.\n",
      "\n",
      "The program begins by defining a `StringSignature` for the task, which includes the claim to be verified, a trajectory of thoughts and actions, and the output fields for the next thought, the name of the next tool to be used, and the arguments for that tool. The `StringSignature` also includes instructions for the task and descriptions of the available tools.\n",
      "\n",
      "The program then defines a `ReAct` module, which takes in the `StringSignature` and a list of tools as input. The `ReAct` module initializes the tools and creates a new `Signature` object that includes the input fields, instructions, and descriptions of the available tools. It also defines a `finish` tool, which signals that the task is complete and marks the final outputs as available.\n",
      "\n",
      "The `ReAct` module then uses a `Predict` function to generate a sequence of thoughts, tool names, and tool arguments based on the input claim and trajectory. It then executes each tool in the sequence and stores the resulting observations in a trajectory dictionary. If the `finish` tool is used, the task is marked as complete and the final outputs are returned.\n",
      "\n",
      "Overall, this program uses a combination of language models and Wikipedia to verify or refute a given claim. It generates a sequence of thoughts and actions to retrieve relevant information from Wikipedia, and then uses that information to make a determination about the claim.\n",
      "\n",
      "[[ ## module ## ]]\n",
      "Predict(claim, trajectory) -> reasoning, titles\n",
      "\n",
      "[[ ## task_demos ## ]]\n",
      "\n",
      "\n",
      "[[ ## basic_instruction ## ]]\n",
      "Find all Wikipedia titles relevant to verifying (or refuting) the claim.\n",
      "\n",
      "[[ ## tip ## ]]\n",
      "Don't be afraid to be creative when creating the new instruction!\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## proposed_instruction ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## proposed_instruction ## ]]\n",
      "Utilize all available Wikipedia resources to thoroughly investigate and gather evidence related to the claim. Generate a comprehensive list of Wikipedia titles that can either support or contradict the claim, and provide a detailed reasoning for each title's relevance.\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "PROPOSED INSTRUCTION: Utilize all available Wikipedia resources to thoroughly investigate and gather evidence related to the claim. Generate a comprehensive list of Wikipedia titles that can either support or contradict the claim, and provide a detailed reasoning for each title's relevance.\n",
      "Using a randomly generated configuration for our grounded proposer.\n",
      "Selected tip: high_stakes\n",
      "PROGRAM DESCRIPTION: This program is designed to solve the task of fact-checking or verifying a given claim using Wikipedia as a source of information. The program uses a pipeline that interacts with language models to generate a sequence of thoughts, tool names, and tool arguments, which are then used to retrieve relevant information from Wikipedia.\n",
      "\n",
      "The program begins by defining a `StringSignature` for the task, which includes the claim to be verified, a trajectory of thoughts and actions, and the output fields for the next thought, the name of the next tool to be used, and the arguments for that tool. The `StringSignature` also includes instructions for the task and descriptions of the available tools.\n",
      "\n",
      "The program then defines a `ReAct` module, which takes in the `StringSignature` and a list of tools as input. The `ReAct` module initializes the tools and creates a new `Signature` object that includes the input fields, instructions, and descriptions of the available tools. It also defines a `finish` tool, which signals that the task is complete and marks the final outputs as available.\n",
      "\n",
      "The `ReAct` module then uses a `Predict` function to generate a sequence of thoughts, tool names, and tool arguments based on the input claim and trajectory. It then executes each tool in the sequence and stores the resulting observations in a trajectory dictionary. If the `finish` tool is used, the task is marked as complete and the final outputs are returned.\n",
      "\n",
      "Overall, this program uses a combination of language models and Wikipedia to verify or refute a given claim. It generates a sequence of thoughts and actions to retrieve relevant information from Wikipedia, and then uses that information to make a determination about the claim.\n",
      "task_demos \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/07 18:52:07 INFO dspy.teleprompt.mipro_optimizer_v2: Proposed Instructions for Predictor 0:\n",
      "\n",
      "2025/01/07 18:52:07 INFO dspy.teleprompt.mipro_optimizer_v2: 0: Find all Wikipedia titles relevant to verifying (or refuting) the claim.\n",
      "\n",
      "You will be given `claim` and your goal is to finish with `titles`.\n",
      "\n",
      "To do this, you will interleave Thought, Tool Name, and Tool Args, and receive a resulting Observation.\n",
      "\n",
      "Thought can reason about the current situation, and Tool Name can be the following types:\n",
      "\n",
      "(1) search_wikipedia, whose description is <desc>Returns top-5 results and then the titles of the top-5 to top-30 results.</desc>. It takes arguments {'query': 'str'} in JSON format.\n",
      "(2) lookup_wikipedia, whose description is <desc>Returns the text of the Wikipedia page, if it exists.</desc>. It takes arguments {'title': 'str'} in JSON format.\n",
      "(3) finish, whose description is <desc>Signals that the final outputs, i.e. `titles`, are now available and marks the task as complete.</desc>. It takes arguments {} in JSON format.\n",
      "\n",
      "2025/01/07 18:52:07 INFO dspy.teleprompt.mipro_optimizer_v2: 1: To verify the given claim, identify the key entities or events mentioned within it. Then, generate a list of potential Wikipedia search queries that could yield relevant information about these entities or events. Utilize the `search_wikipedia` tool to execute these queries and retrieve the top-5 results. Extract the titles of the top-5 to top-30 results from these search results. If necessary, use the `lookup_wikipedia` tool to gather more detailed information from specific Wikipedia pages. Once you have gathered sufficient evidence, use the `finish` tool to signal that the task is complete and provide the final list of relevant Wikipedia titles.\n",
      "\n",
      "2025/01/07 18:52:07 INFO dspy.teleprompt.mipro_optimizer_v2: 2: Given a claim, your task is to identify relevant Wikipedia titles that can be used to verify or refute the claim. You will do this by generating a sequence of thoughts, tool names, and tool arguments, and then executing the corresponding tools to retrieve information from Wikipedia. Your final output should be a list of Wikipedia titles that are relevant to the claim.\n",
      "\n",
      "To begin, analyze the claim and generate a thought that describes the initial situation and your plan for identifying relevant titles. Then, choose a tool and provide the necessary arguments for executing that tool. Repeat this process until you have identified all relevant titles, and then use the `finish` tool to signal that the task is complete.\n",
      "\n",
      "Remember to follow the instructions carefully and use the available tools appropriately. Your output should include the fields `next_thought`, `next_tool_name`, and `next_tool_args`.\n",
      "\n",
      "2025/01/07 18:52:07 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "\n",
      "2025/01/07 18:52:07 INFO dspy.teleprompt.mipro_optimizer_v2: Proposed Instructions for Predictor 1:\n",
      "\n",
      "2025/01/07 18:52:07 INFO dspy.teleprompt.mipro_optimizer_v2: 0: Find all Wikipedia titles relevant to verifying (or refuting) the claim.\n",
      "\n",
      "2025/01/07 18:52:07 INFO dspy.teleprompt.mipro_optimizer_v2: 1: Utilize all available Wikipedia resources to thoroughly investigate and gather evidence related to the claim. Generate a comprehensive list of Wikipedia titles that can either support or contradict the claim, and provide a detailed reasoning for each title's relevance.\n",
      "\n",
      "2025/01/07 18:52:07 INFO dspy.teleprompt.mipro_optimizer_v2: 2: You are a fact-checking assistant for a high-profile legal case. Your task is to find all Wikipedia titles that are relevant to verifying or refuting the claim. This is a critical step in building a strong case, so it's important to be thorough and accurate. Use your language model capabilities to generate a sequence of thoughts, tool names, and tool arguments that will help you retrieve relevant information from Wikipedia. Once you have gathered all the necessary titles, signal that the task is complete. Remember, the outcome of this case depends on your ability to find the right information.\n",
      "\n",
      "2025/01/07 18:52:07 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "\n",
      "2025/01/07 18:52:07 INFO dspy.teleprompt.mipro_optimizer_v2: Evaluating the default program...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-01-07T18:52:07.305134]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `dataset_description` (str): A description of the dataset that we are using.\n",
      "2. `program_code` (str): Language model program designed to solve a particular task.\n",
      "3. `program_description` (str): Summary of the task the program is designed to solve, and how it goes about solving it.\n",
      "4. `module` (str): The module to create an instruction for.\n",
      "5. `task_demos` (str): Example inputs/outputs of our module.\n",
      "6. `basic_instruction` (str): Basic instruction.\n",
      "7. `tip` (str): A suggestion for how to go about generating the new instruction.\n",
      "\n",
      "Your output fields are:\n",
      "1. `proposed_instruction` (str): Propose an instruction that will be used to prompt a Language Model to perform this task.\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## dataset_description ## ]]\n",
      "{dataset_description}\n",
      "\n",
      "[[ ## program_code ## ]]\n",
      "{program_code}\n",
      "\n",
      "[[ ## program_description ## ]]\n",
      "{program_description}\n",
      "\n",
      "[[ ## module ## ]]\n",
      "{module}\n",
      "\n",
      "[[ ## task_demos ## ]]\n",
      "{task_demos}\n",
      "\n",
      "[[ ## basic_instruction ## ]]\n",
      "{basic_instruction}\n",
      "\n",
      "[[ ## tip ## ]]\n",
      "{tip}\n",
      "\n",
      "[[ ## proposed_instruction ## ]]\n",
      "{proposed_instruction}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        Use the information below to learn about a task that we are trying to solve using calls to an LM, then generate a new instruction that will be used to prompt a Language Model to better solve the task.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## dataset_description ## ]]\n",
      "The dataset comprises concise claims connecting topics or individuals to specific details or events, indicating potential use for fact-checking or knowledge validation. Each claim is associated with titles that may act as evidence or context, and the dataset covers a wide range of domains including film, railway routes, and martial arts. The brevity and clarity of the claims suggest their use in tasks requiring direct factual statements.\n",
      "\n",
      "[[ ## program_code ## ]]\n",
      "StringSignature(claim, trajectory -> next_thought, next_tool_name, next_tool_args\n",
      "    instructions=\"Find all Wikipedia titles relevant to verifying (or refuting) the claim.\\n\\nYou will be given `claim` and your goal is to finish with `titles`.\\n\\nTo do this, you will interleave Thought, Tool Name, and Tool Args, and receive a resulting Observation.\\n\\nThought can reason about the current situation, and Tool Name can be the following types:\\n\\n(1) search_wikipedia, whose description is <desc>Returns top-5 results and then the titles of the top-5 to top-30 results.</desc>. It takes arguments {'query': 'str'} in JSON format.\\n(2) lookup_wikipedia, whose description is <desc>Returns the text of the Wikipedia page, if it exists.</desc>. It takes arguments {'title': 'str'} in JSON format.\\n(3) finish, whose description is <desc>Signals that the final outputs, i.e. `titles`, are now available and marks the task as complete.</desc>. It takes arguments {} in JSON format.\"\n",
      "    claim = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Claim:', 'desc': '${claim}'})\n",
      "    trajectory = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Trajectory:', 'desc': '${trajectory}'})\n",
      "    next_thought = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Next Thought:', 'desc': '${next_thought}'})\n",
      "    next_tool_name = Field(annotation=Literal['search_wikipedia', 'lookup_wikipedia', 'finish'] required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Next Tool Name:', 'desc': '${next_tool_name}'})\n",
      "    next_tool_args = Field(annotation=dict[str, Any] required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Next Tool Args:', 'desc': '${next_tool_args}'})\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "StringSignature(claim, trajectory -> reasoning, titles\n",
      "    instructions='Find all Wikipedia titles relevant to verifying (or refuting) the claim.'\n",
      "    claim = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Claim:', 'desc': '${claim}'})\n",
      "    trajectory = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Trajectory:', 'desc': '${trajectory}'})\n",
      "    reasoning = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${reasoning}', '__dspy_field_type': 'output'})\n",
      "    titles = Field(annotation=list[str] required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Titles:', 'desc': '${titles}'})\n",
      ")\n",
      "\n",
      "class ReAct(Module):\n",
      "    def __init__(self, signature, tools: list[Callable], max_iters=5):\n",
      "        \"\"\"\n",
      "        `tools` is either a list of functions, callable classes, or `dspy.Tool` instances.\n",
      "        \"\"\"\n",
      "\n",
      "        self.signature = signature = ensure_signature(signature)\n",
      "        self.max_iters = max_iters\n",
      "\n",
      "        tools = [t if isinstance(t, Tool) or hasattr(t, \"input_variable\") else Tool(t) for t in tools]\n",
      "        tools = {tool.name: tool for tool in tools}\n",
      "\n",
      "        inputs = \", \".join([f\"`{k}`\" for k in signature.input_fields.keys()])\n",
      "        outputs = \", \".join([f\"`{k}`\" for k in signature.output_fields.keys()])\n",
      "        instr = [f\"{signature.instructions}\\n\"] if signature.instructions else []\n",
      "\n",
      "        instr.extend(\n",
      "            [\n",
      "                f\"You will be given {inputs} and your goal is to finish with {outputs}.\\n\",\n",
      "                \"To do this, you will interleave Thought, Tool Name, and Tool Args, and receive a resulting Observation.\\n\",\n",
      "                \"Thought can reason about the current situation, and Tool Name can be the following types:\\n\",\n",
      "            ]\n",
      "        )\n",
      "\n",
      "        finish_desc = (\n",
      "            f\"Signals that the final outputs, i.e. {outputs}, are now available and marks the task as complete.\"\n",
      "        )\n",
      "        finish_args = {}  # k: v.annotation for k, v in signature.output_fields.items()}\n",
      "        tools[\"finish\"] = Tool(func=lambda **kwargs: \"Completed.\", name=\"finish\", desc=finish_desc, args=finish_args)\n",
      "\n",
      "        for idx, tool in enumerate(tools.values()):\n",
      "            args = tool.args if hasattr(tool, \"args\") else str({tool.input_variable: str})\n",
      "            desc = (f\", whose description is <desc>{tool.desc}</desc>.\" if tool.desc else \".\").replace(\"\\n\", \"  \")\n",
      "            desc += f\" It takes arguments {args} in JSON format.\"\n",
      "            instr.append(f\"({idx+1}) {tool.name}{desc}\")\n",
      "\n",
      "        react_signature = (\n",
      "            dspy.Signature({**signature.input_fields}, \"\\n\".join(instr))\n",
      "            .append(\"trajectory\", dspy.InputField(), type_=str)\n",
      "            .append(\"next_thought\", dspy.OutputField(), type_=str)\n",
      "            .append(\"next_tool_name\", dspy.OutputField(), type_=Literal[tuple(tools.keys())])\n",
      "            .append(\"next_tool_args\", dspy.OutputField(), type_=dict[str, Any])\n",
      "        )\n",
      "\n",
      "        fallback_signature = dspy.Signature(\n",
      "            {**signature.input_fields, **signature.output_fields}, signature.instructions\n",
      "        ).append(\"trajectory\", dspy.InputField(), type_=str)\n",
      "\n",
      "        self.tools = tools\n",
      "        self.react = dspy.Predict(react_signature)\n",
      "        self.extract = dspy.ChainOfThought(fallback_signature)\n",
      "\n",
      "    def forward(self, **input_args):\n",
      "        def format(trajectory: dict[str, Any], last_iteration: bool):\n",
      "            adapter = dspy.settings.adapter or dspy.ChatAdapter()\n",
      "            trajectory_signature = dspy.Signature(f\"{', '.join(trajectory.keys())} -> x\")\n",
      "            return adapter.format_fields(trajectory_signature, trajectory, role=\"user\")\n",
      "\n",
      "        trajectory = {}\n",
      "        for idx in range(self.max_iters):\n",
      "            pred = self.react(**input_args, trajectory=format(trajectory, last_iteration=(idx == self.max_iters - 1)))\n",
      "\n",
      "            trajectory[f\"thought_{idx}\"] = pred.next_thought\n",
      "            trajectory[f\"tool_name_{idx}\"] = pred.next_tool_name\n",
      "            trajectory[f\"tool_args_{idx}\"] = pred.next_tool_args\n",
      "\n",
      "            try:\n",
      "                trajectory[f\"observation_{idx}\"] = self.tools[pred.next_tool_name](**pred.next_tool_args)\n",
      "            except Exception as e:\n",
      "                trajectory[f\"observation_{idx}\"] = f\"Failed to execute: {e}\"\n",
      "\n",
      "            if pred.next_tool_name == \"finish\":\n",
      "                break\n",
      "\n",
      "        extract = self.extract(**input_args, trajectory=format(trajectory, last_iteration=False))\n",
      "        return dspy.Prediction(trajectory=trajectory, **extract)\n",
      "\n",
      "\n",
      "[[ ## program_description ## ]]\n",
      "This program is designed to solve the task of fact-checking or verifying a given claim using Wikipedia as a source of information. The program uses a pipeline that interacts with language models to generate a sequence of thoughts, tool names, and tool arguments, which are then used to retrieve relevant information from Wikipedia.\n",
      "\n",
      "The program begins by defining a `StringSignature` for the task, which includes the claim to be verified, a trajectory of thoughts and actions, and the output fields for the next thought, the name of the next tool to be used, and the arguments for that tool. The `StringSignature` also includes instructions for the task and descriptions of the available tools.\n",
      "\n",
      "The program then defines a `ReAct` module, which takes in the `StringSignature` and a list of tools as input. The `ReAct` module initializes the tools and creates a new `Signature` object that includes the input fields, instructions, and descriptions of the available tools. It also defines a `finish` tool, which signals that the task is complete and marks the final outputs as available.\n",
      "\n",
      "The `ReAct` module then uses a `Predict` function to generate a sequence of thoughts, tool names, and tool arguments based on the input claim and trajectory. It then executes each tool in the sequence and stores the resulting observations in a trajectory dictionary. If the `finish` tool is used, the task is marked as complete and the final outputs are returned.\n",
      "\n",
      "Overall, this program uses a combination of language models and Wikipedia to verify or refute a given claim. It generates a sequence of thoughts and actions to retrieve relevant information from Wikipedia, and then uses that information to make a determination about the claim.\n",
      "\n",
      "[[ ## module ## ]]\n",
      "Predict(claim, trajectory) -> reasoning, titles\n",
      "\n",
      "[[ ## task_demos ## ]]\n",
      "\n",
      "\n",
      "[[ ## basic_instruction ## ]]\n",
      "Find all Wikipedia titles relevant to verifying (or refuting) the claim.\n",
      "\n",
      "[[ ## tip ## ]]\n",
      "The instruction should include a high stakes scenario in which the LM must solve the task!\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## proposed_instruction ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## proposed_instruction ## ]]\n",
      "You are a fact-checking assistant for a high-profile legal case. Your task is to find all Wikipedia titles that are relevant to verifying or refuting the claim. This is a critical step in building a strong case, so it's important to be thorough and accurate. Use your language model capabilities to generate a sequence of thoughts, tool names, and tool arguments that will help you retrieve relevant information from Wikipedia. Once you have gathered all the necessary titles, signal that the task is complete. Remember, the outcome of this case depends on your ability to find the right information.\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "PROPOSED INSTRUCTION: You are a fact-checking assistant for a high-profile legal case. Your task is to find all Wikipedia titles that are relevant to verifying or refuting the claim. This is a critical step in building a strong case, so it's important to be thorough and accurate. Use your language model capabilities to generate a sequence of thoughts, tool names, and tool arguments that will help you retrieve relevant information from Wikipedia. Once you have gathered all the necessary titles, signal that the task is complete. Remember, the outcome of this case depends on your ability to find the right information.\n",
      "  0%|                                                                                                                                                                    | 0/16 [00:00<?, ?it/s]**pred titles ** []\n",
      "'\n",
      "'\n",
      "---> gold titles ['Baboo (airline)', 'Lugano Airport', 'Darwin Airline']\n",
      "Average Metric: 0.00 / 1 (0.0%):   6%|███████▋                                                                                                                   | 1/16 [00:22<05:36, 22.46s/it]**pred titles ** ['Zak Ové', 'A. Edward Sutherland']\n",
      "'\n",
      "'\n",
      "---> gold titles ['Horace Ové', 'Zak Ové', 'A. Edward Sutherland']\n",
      "Average Metric: 0.67 / 2 (33.3%):  12%|███████████████▎                                                                                                          | 2/16 [00:27<02:54, 12.48s/it]**pred titles ** ['Bing Bong (single)', 'Social Distortion']\n",
      "'\n",
      "'\n",
      "---> gold titles ['Super Furry Animals', 'Social Distortion', 'Bing Bong']\n",
      "Average Metric: 1.00 / 3 (33.3%):  19%|██████████████████████▉                                                                                                   | 3/16 [00:28<01:29,  6.86s/it]**pred titles ** [\"Beethoven's contemporaries\", \"Beethoven's opinion of Luigi Cherubini\", \"Beethoven's opinion of Franz Schreker\"]\n",
      "'\n",
      "'\n",
      "---> gold titles ['Luigi Cherubini', 'Franz Schreker', 'Irrelohe']\n",
      "Average Metric: 1.00 / 4 (25.0%):  25%|██████████████████████████████▌                                                                                           | 4/16 [00:32<01:12,  6.07s/it]**pred titles ** ['David Bowman (botanist)', 'Carlina']\n",
      "'\n",
      "'\n",
      "---> gold titles ['David Bowman (botanist)', 'Dieffenbachia', 'Carlina']\n",
      "Average Metric: 1.67 / 5 (33.3%):  31%|██████████████████████████████████████▏                                                                                   | 5/16 [00:37<00:59,  5.43s/it]**pred titles ** ['50th Berlin International Film Festival', 'Dancing in the Dark (2000 film)', 'Name of the actor who was a United States Navy Combat veteran in World War II']\n",
      "'\n",
      "'\n",
      "---> gold titles ['Magnolia (film)', '50th Berlin International Film Festival', 'Jason Robards']\n",
      "Average Metric: 2.00 / 6 (33.3%):  38%|█████████████████████████████████████████████▊                                                                            | 6/16 [00:44<01:01,  6.19s/it]**pred titles ** ['Harper Lee', 'Vladimir Vladimirovich Nabokov']\n",
      "'\n",
      "'\n",
      "---> gold titles ['Vladimir Nabokov', 'Harper Lee', 'List of To Kill a Mockingbird characters']\n",
      "Average Metric: 2.33 / 7 (33.3%):  44%|█████████████████████████████████████████████████████▍                                                                    | 7/16 [00:46<00:42,  4.71s/it]**pred titles ** []\n",
      "'\n",
      "'\n",
      "---> gold titles ['The People vs.', 'Welcome 2 Detroit (song)', 'Proof (rapper)']\n",
      "Average Metric: 2.33 / 8 (29.2%):  50%|█████████████████████████████████████████████████████████████                                                             | 8/16 [00:52<00:40,  5.07s/it]**pred titles ** []\n",
      "'\n",
      "'\n",
      "---> gold titles ['Leader of Fine Gael', 'Leo Varadkar', 'Michael Noonan']\n",
      "Average Metric: 2.33 / 9 (25.9%):  56%|████████████████████████████████████████████████████████████████████▋                                                     | 9/16 [01:07<00:56,  8.10s/it]**pred titles ** ['Swiss company headquartered in Clayton County, Georgia', 'Candi Kubeck']\n",
      "'\n",
      "'\n",
      "---> gold titles ['ValuJet Airlines', 'ValuJet Flight 592', 'Candi Kubeck']\n",
      "Average Metric: 2.67 / 10 (26.7%):  62%|███████████████████████████████████████████████████████████████████████████                                             | 10/16 [01:32<01:20, 13.37s/it]**pred titles ** ['Wiliwili tree', 'Acacia koa', 'Dry forests of Hawaii', 'Pea family', 'Hawaiian tree species']\n",
      "'\n",
      "'\n",
      "---> gold titles ['Acacia koa', 'Hawaiian tropical dry forests', 'Wiliwili']\n",
      "Average Metric: 3.00 / 11 (27.3%):  69%|██████████████████████████████████████████████████████████████████████████████████▌                                     | 11/16 [01:32<00:47,  9.40s/it]**pred titles ** ['Rhinestone', 'Rhinestone (film)']\n",
      "'\n",
      "'\n",
      "---> gold titles ['Phil Alden Robinson', 'David Nixon (director)', 'Rhinestone (film)']\n",
      "Average Metric: 3.33 / 12 (27.8%):  75%|██████████████████████████████████████████████████████████████████████████████████████████                              | 12/16 [01:33<00:26,  6.67s/it]**pred titles ** []\n",
      "'\n",
      "'\n",
      "---> gold titles [\"Somebody's Daughter\", 'D.C. Cab', 'Max Gail']\n",
      "Average Metric: 3.33 / 13 (25.6%):  81%|█████████████████████████████████████████████████████████████████████████████████████████████████▌                      | 13/16 [01:34<00:14,  4.96s/it]**pred titles ** ['Chengiopanax', 'Amaryllis']\n",
      "'\n",
      "'\n",
      "---> gold titles ['Chengiopanax sciadophylloides', 'Amaryllis', 'Eleutherococcus']\n",
      "Average Metric: 3.67 / 14 (26.2%):  88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████               | 14/16 [01:41<00:11,  5.66s/it]**pred titles ** ['Dalila Bela', 'Anne of Green Gables']\n",
      "'\n",
      "'\n",
      "---> gold titles ['Amybeth McNulty', 'Anne (TV series)', 'Dalila Bela']\n",
      "Average Metric: 4.00 / 15 (26.7%):  94%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌       | 15/16 [01:43<00:04,  4.41s/it]**pred titles ** ['Rachel Egglestone-Evans', 'InStyle (magazine)']\n",
      "'\n",
      "'\n",
      "---> gold titles ['Rachel Egglestone-Evans', 'InStyle', 'Vintage Life']\n",
      "Average Metric: 4.33 / 16 (27.1%): 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [01:46<00:00,  6.64s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/07 18:53:53 INFO dspy.evaluate.evaluate: Average Metric: 4.333333333333333 / 16 (27.1%)\n",
      "2025/01/07 18:53:53 INFO dspy.teleprompt.mipro_optimizer_v2: Default program score: 27.08\n",
      "\n",
      "2025/01/07 18:53:53 INFO dspy.teleprompt.mipro_optimizer_v2: ==> STEP 3: FINDING OPTIMAL PROMPT PARAMETERS <==\n",
      "2025/01/07 18:53:53 INFO dspy.teleprompt.mipro_optimizer_v2: We will evaluate the program over a series of trials with different combinations of instructions and few-shot examples to find the optimal combination using Bayesian Optimization.\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/optuna/_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "2025/01/07 18:53:53 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 1 / 7 =====\n",
      "2025/01/07 18:53:53 INFO dspy.teleprompt.mipro_optimizer_v2: Evaluating the following candidate program...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictor 0\n",
      "i: To verify the given claim, identify the key entities or events mentioned within it. Then, generate a list of potential Wikipedia search queries that could yield relevant information about these entities or events. Utilize the `search_wikipedia` tool to execute these queries and retrieve the top-5 results. Extract the titles of the top-5 to top-30 results from these search results. If necessary, use the `lookup_wikipedia` tool to gather more detailed information from specific Wikipedia pages. Once you have gathered sufficient evidence, use the `finish` tool to signal that the task is complete and provide the final list of relevant Wikipedia titles.\n",
      "p: Next Tool Args:\n",
      "Predictor 1\n",
      "i: Find all Wikipedia titles relevant to verifying (or refuting) the claim.\n",
      "p: Titles:\n",
      "\n",
      "\n",
      "  0%|                                                                                                                                                                    | 0/16 [00:00<?, ?it/s]**pred titles ** []\n",
      "'\n",
      "'\n",
      "---> gold titles ['Baboo (airline)', 'Lugano Airport', 'Darwin Airline']\n",
      "Average Metric: 0.00 / 1 (0.0%):   6%|███████▋                                                                                                                   | 1/16 [00:35<08:52, 35.51s/it]**pred titles ** [\"Somebody's Daughter's star\", 'D.C. Cab', 'Barney Miller']\n",
      "'\n",
      "'\n",
      "---> gold titles [\"Somebody's Daughter\", 'D.C. Cab', 'Max Gail']\n",
      "Average Metric: 0.33 / 2 (16.7%):  12%|███████████████▎                                                                                                          | 2/16 [00:50<05:29, 23.50s/it]**pred titles ** []\n",
      "'\n",
      "'\n",
      "---> gold titles ['Horace Ové', 'Zak Ové', 'A. Edward Sutherland']\n",
      "Average Metric: 0.33 / 3 (11.1%):  19%|██████████████████████▉                                                                                                   | 3/16 [01:28<06:30, 30.05s/it]**pred titles ** []\n",
      "'\n",
      "'\n",
      "---> gold titles ['ValuJet Airlines', 'ValuJet Flight 592', 'Candi Kubeck']\n",
      "Average Metric: 0.33 / 4 (8.3%):  25%|██████████████████████████████▊                                                                                            | 4/16 [01:44<04:56, 24.67s/it]**pred titles ** []\n",
      "'\n",
      "'\n",
      "---> gold titles ['Super Furry Animals', 'Social Distortion', 'Bing Bong']\n",
      "Average Metric: 0.33 / 5 (6.7%):  31%|██████████████████████████████████████▍                                                                                    | 5/16 [01:48<03:08, 17.16s/it]**pred titles ** ['Dalila Bela', 'Anne with an E', 'Anne of Green Gables']\n",
      "'\n",
      "'\n",
      "---> gold titles ['Amybeth McNulty', 'Anne (TV series)', 'Dalila Bela']\n",
      "Average Metric: 0.67 / 6 (11.1%):  38%|█████████████████████████████████████████████▊                                                                            | 6/16 [01:55<02:15, 13.54s/it]**pred titles ** ['Bowmania', 'Carlina (plant)']\n",
      "'\n",
      "'\n",
      "---> gold titles ['David Bowman (botanist)', 'Dieffenbachia', 'Carlina']\n",
      "Average Metric: 0.67 / 7 (9.5%):  44%|█████████████████████████████████████████████████████▊                                                                     | 7/16 [01:55<01:22,  9.16s/it]**pred titles ** ['Vladimir Nabokov', 'Harper Lee']\n",
      "'\n",
      "'\n",
      "---> gold titles ['Vladimir Nabokov', 'Harper Lee', 'List of To Kill a Mockingbird characters']\n",
      "Average Metric: 1.33 / 8 (16.7%):  50%|█████████████████████████████████████████████████████████████                                                             | 8/16 [01:58<00:57,  7.20s/it]**pred titles ** ['50th Berlin International Film Festival', 'Golden Bear', 'musical film', 'United States Navy Combat veteran actor']\n",
      "'\n",
      "'\n",
      "---> gold titles ['Magnolia (film)', '50th Berlin International Film Festival', 'Jason Robards']\n",
      "Average Metric: 1.67 / 9 (18.5%):  56%|████████████████████████████████████████████████████████████████████▋                                                     | 9/16 [02:00<00:39,  5.57s/it]**pred titles ** ['Wiliwili', 'Acacia koa', 'Pea family']\n",
      "'\n",
      "'\n",
      "---> gold titles ['Acacia koa', 'Hawaiian tropical dry forests', 'Wiliwili']\n",
      "Average Metric: 2.33 / 10 (23.3%):  62%|███████████████████████████████████████████████████████████████████████████                                             | 10/16 [02:02<00:27,  4.63s/it]**pred titles ** []\n",
      "'\n",
      "'\n",
      "---> gold titles ['Phil Alden Robinson', 'David Nixon (director)', 'Rhinestone (film)']\n",
      "Average Metric: 2.33 / 11 (21.2%):  69%|██████████████████████████████████████████████████████████████████████████████████▌                                     | 11/16 [02:09<00:25,  5.15s/it]**pred titles ** ['Rachel Egglestone-Evans', 'InStyle (magazine)']\n",
      "'\n",
      "'\n",
      "---> gold titles ['Rachel Egglestone-Evans', 'InStyle', 'Vintage Life']\n",
      "Average Metric: 2.67 / 12 (22.2%):  75%|██████████████████████████████████████████████████████████████████████████████████████████                              | 12/16 [02:09<00:15,  3.81s/it]**pred titles ** ['Michael Noonan', 'Minister for Finance (Ireland)', 'Minister for Social Protection (Ireland)']\n",
      "'\n",
      "'\n",
      "---> gold titles ['Leader of Fine Gael', 'Leo Varadkar', 'Michael Noonan']\n",
      "Average Metric: 3.00 / 13 (23.1%):  81%|█████████████████████████████████████████████████████████████████████████████████████████████████▌                      | 13/16 [02:12<00:10,  3.47s/it]**pred titles ** ['Chengiopanax', 'Eleutherococcus sciadophylloides', 'Amaryllis (plant)', 'Amaryllis (poem)', 'Amaryllis (given name)']\n",
      "'\n",
      "'\n",
      "---> gold titles ['Chengiopanax sciadophylloides', 'Amaryllis', 'Eleutherococcus']\n",
      "Average Metric: 3.00 / 14 (21.4%):  88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████               | 14/16 [02:17<00:07,  3.89s/it]**pred titles ** [\"Beethoven's opinion on Luigi Cherubini\", \"Irrelohe composer and Beethoven's opinion\"]\n",
      "'\n",
      "'\n",
      "---> gold titles ['Luigi Cherubini', 'Franz Schreker', 'Irrelohe']\n",
      "Average Metric: 3.00 / 15 (20.0%):  94%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌       | 15/16 [02:22<00:04,  4.14s/it]**pred titles ** ['Detroit rappers born in 1973', 'Trick-Trick debut album', 'Welcome 2 Detroit song', 'Trick-Trick guest appearances']\n",
      "'\n",
      "'\n",
      "---> gold titles ['The People vs.', 'Welcome 2 Detroit (song)', 'Proof (rapper)']\n",
      "Average Metric: 3.00 / 16 (18.7%): 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [02:30<00:00,  9.41s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/07 18:56:24 INFO dspy.evaluate.evaluate: Average Metric: 2.9999999999999996 / 16 (18.7%)\n",
      "2025/01/07 18:56:24 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 18.75 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 2', 'Predictor 1: Instruction 0', 'Predictor 1: Few-Shot Set 2'].\n",
      "2025/01/07 18:56:24 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [27.08, 18.75]\n",
      "2025/01/07 18:56:24 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 27.08\n",
      "2025/01/07 18:56:24 INFO dspy.teleprompt.mipro_optimizer_v2: =======================\n",
      "\n",
      "\n",
      "2025/01/07 18:56:24 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 2 / 7 =====\n",
      "2025/01/07 18:56:24 INFO dspy.teleprompt.mipro_optimizer_v2: Evaluating the following candidate program...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictor 0\n",
      "i: Find all Wikipedia titles relevant to verifying (or refuting) the claim.\n",
      "\n",
      "You will be given `claim` and your goal is to finish with `titles`.\n",
      "\n",
      "To do this, you will interleave Thought, Tool Name, and Tool Args, and receive a resulting Observation.\n",
      "\n",
      "Thought can reason about the current situation, and Tool Name can be the following types:\n",
      "\n",
      "(1) search_wikipedia, whose description is <desc>Returns top-5 results and then the titles of the top-5 to top-30 results.</desc>. It takes arguments {'query': 'str'} in JSON format.\n",
      "(2) lookup_wikipedia, whose description is <desc>Returns the text of the Wikipedia page, if it exists.</desc>. It takes arguments {'title': 'str'} in JSON format.\n",
      "(3) finish, whose description is <desc>Signals that the final outputs, i.e. `titles`, are now available and marks the task as complete.</desc>. It takes arguments {} in JSON format.\n",
      "p: Next Tool Args:\n",
      "Predictor 1\n",
      "i: Utilize all available Wikipedia resources to thoroughly investigate and gather evidence related to the claim. Generate a comprehensive list of Wikipedia titles that can either support or contradict the claim, and provide a detailed reasoning for each title's relevance.\n",
      "p: Titles:\n",
      "\n",
      "\n",
      "  0%|                                                                                                                                                                    | 0/16 [00:00<?, ?it/s]**pred titles ** []\n",
      "'\n",
      "'\n",
      "---> gold titles ['Baboo (airline)', 'Lugano Airport', 'Darwin Airline']\n",
      "Average Metric: 0.00 / 1 (0.0%):   6%|███████▋                                                                                                                   | 1/16 [00:05<01:26,  5.79s/it]**pred titles ** ['Beethoven and Cherubini', 'Franz Schreker', \"Beethoven's contemporaries\"]\n",
      "'\n",
      "'\n",
      "---> gold titles ['Luigi Cherubini', 'Franz Schreker', 'Irrelohe']\n",
      "Average Metric: 0.33 / 2 (16.7%):  12%|███████████████▎                                                                                                          | 2/16 [00:06<00:36,  2.58s/it]**pred titles ** ['Zak Ové', 'A. Edward Sutherland']\n",
      "'\n",
      "'\n",
      "---> gold titles ['Horace Ové', 'Zak Ové', 'A. Edward Sutherland']\n",
      "Average Metric: 1.00 / 3 (33.3%):  19%|██████████████████████▉                                                                                                   | 3/16 [00:08<00:34,  2.66s/it]**pred titles ** ['David Bowman (botanist)', 'Carlina', 'Scleranthus']\n",
      "'\n",
      "'\n",
      "---> gold titles ['David Bowman (botanist)', 'Dieffenbachia', 'Carlina']\n",
      "Average Metric: 1.67 / 4 (41.7%):  25%|██████████████████████████████▌                                                                                           | 4/16 [00:09<00:21,  1.82s/it]**pred titles ** ['Bing Bong (single)', 'Social Distortion']\n",
      "'\n",
      "'\n",
      "---> gold titles ['Super Furry Animals', 'Social Distortion', 'Bing Bong']\n",
      "Average Metric: 2.00 / 5 (40.0%):  31%|██████████████████████████████████████▏                                                                                   | 5/16 [00:09<00:13,  1.22s/it]**pred titles ** []\n",
      "'\n",
      "'\n",
      "---> gold titles ['Leader of Fine Gael', 'Leo Varadkar', 'Michael Noonan']\n",
      "Average Metric: 2.00 / 6 (33.3%):  31%|██████████████████████████████████████▏                                                                                   | 5/16 [00:09<00:13,  1.22s/it]**pred titles ** ['Harper Lee', 'Vladimir Vladimirovich Nabokov']\n",
      "'\n",
      "'\n",
      "---> gold titles ['Vladimir Nabokov', 'Harper Lee', 'List of To Kill a Mockingbird characters']\n",
      "Average Metric: 2.33 / 7 (33.3%):  44%|█████████████████████████████████████████████████████▍                                                                    | 7/16 [00:10<00:07,  1.23it/s]**pred titles ** ['Detroit rapper born 1973', \"Trick-Trick's debut studio album\", 'Welcome 2 Detroit']\n",
      "'\n",
      "'\n",
      "---> gold titles ['The People vs.', 'Welcome 2 Detroit (song)', 'Proof (rapper)']\n",
      "Average Metric: 2.33 / 8 (29.2%):  50%|█████████████████████████████████████████████████████████████                                                             | 8/16 [00:10<00:05,  1.60it/s]**pred titles ** ['Dancing in the Dark (2000 film)', 'List of United States Navy recipients of the Navy Cross', 'World War II']\n",
      "'\n",
      "'\n",
      "---> gold titles ['Magnolia (film)', '50th Berlin International Film Festival', 'Jason Robards']\n",
      "Average Metric: 2.33 / 9 (25.9%):  56%|████████████████████████████████████████████████████████████████████▋                                                     | 9/16 [00:12<00:07,  1.12s/it]**pred titles ** []\n",
      "'\n",
      "'\n",
      "---> gold titles ['Acacia koa', 'Hawaiian tropical dry forests', 'Wiliwili']\n",
      "Average Metric: 2.33 / 10 (23.3%):  62%|███████████████████████████████████████████████████████████████████████████                                             | 10/16 [00:13<00:05,  1.01it/s]**pred titles ** []\n",
      "'\n",
      "'\n",
      "---> gold titles ['Phil Alden Robinson', 'David Nixon (director)', 'Rhinestone (film)']\n",
      "Average Metric: 2.33 / 11 (21.2%):  69%|██████████████████████████████████████████████████████████████████████████████████▌                                     | 11/16 [00:14<00:04,  1.17it/s]**pred titles ** ['Rachel Egglestone-Evans', 'InStyle']\n",
      "'\n",
      "'\n",
      "---> gold titles ['Rachel Egglestone-Evans', 'InStyle', 'Vintage Life']\n",
      "Average Metric: 3.00 / 12 (25.0%):  75%|██████████████████████████████████████████████████████████████████████████████████████████                              | 12/16 [00:14<00:03,  1.31it/s]**pred titles ** []\n",
      "'\n",
      "'\n",
      "---> gold titles [\"Somebody's Daughter\", 'D.C. Cab', 'Max Gail']\n",
      "Average Metric: 3.00 / 13 (23.1%):  81%|█████████████████████████████████████████████████████████████████████████████████████████████████▌                      | 13/16 [00:16<00:03,  1.10s/it]**pred titles ** ['Dalila Bela', 'Anne of Green Gables (TV series)', 'Anne of Green Gables (novel)']\n",
      "'\n",
      "'\n",
      "---> gold titles ['Amybeth McNulty', 'Anne (TV series)', 'Dalila Bela']\n",
      "Average Metric: 3.33 / 14 (23.8%):  88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████               | 14/16 [00:17<00:01,  1.03it/s]**pred titles ** ['Delta Air Lines', 'Swiss Global Air Lines', 'Candi Kubeck']\n",
      "'\n",
      "'\n",
      "---> gold titles ['ValuJet Airlines', 'ValuJet Flight 592', 'Candi Kubeck']\n",
      "Average Metric: 3.67 / 15 (24.4%):  94%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌       | 15/16 [00:18<00:00,  1.07it/s]**pred titles ** ['Chengiopanax', 'Amaryllis']\n",
      "'\n",
      "'\n",
      "---> gold titles ['Chengiopanax sciadophylloides', 'Amaryllis', 'Eleutherococcus']\n",
      "Average Metric: 4.00 / 16 (25.0%): 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:18<00:00,  1.14s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/07 18:56:42 INFO dspy.evaluate.evaluate: Average Metric: 4.0 / 16 (25.0%)\n",
      "2025/01/07 18:56:42 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 25.0 with parameters ['Predictor 0: Instruction 0', 'Predictor 0: Few-Shot Set 1', 'Predictor 1: Instruction 1', 'Predictor 1: Few-Shot Set 1'].\n",
      "2025/01/07 18:56:42 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [27.08, 18.75, 25.0]\n",
      "2025/01/07 18:56:42 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 27.08\n",
      "2025/01/07 18:56:42 INFO dspy.teleprompt.mipro_optimizer_v2: =======================\n",
      "\n",
      "\n",
      "2025/01/07 18:56:42 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 3 / 7 =====\n",
      "2025/01/07 18:56:42 INFO dspy.teleprompt.mipro_optimizer_v2: Evaluating the following candidate program...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictor 0\n",
      "i: Given a claim, your task is to identify relevant Wikipedia titles that can be used to verify or refute the claim. You will do this by generating a sequence of thoughts, tool names, and tool arguments, and then executing the corresponding tools to retrieve information from Wikipedia. Your final output should be a list of Wikipedia titles that are relevant to the claim.\n",
      "\n",
      "To begin, analyze the claim and generate a thought that describes the initial situation and your plan for identifying relevant titles. Then, choose a tool and provide the necessary arguments for executing that tool. Repeat this process until you have identified all relevant titles, and then use the `finish` tool to signal that the task is complete.\n",
      "\n",
      "Remember to follow the instructions carefully and use the available tools appropriately. Your output should include the fields `next_thought`, `next_tool_name`, and `next_tool_args`.\n",
      "p: Next Tool Args:\n",
      "Predictor 1\n",
      "i: You are a fact-checking assistant for a high-profile legal case. Your task is to find all Wikipedia titles that are relevant to verifying or refuting the claim. This is a critical step in building a strong case, so it's important to be thorough and accurate. Use your language model capabilities to generate a sequence of thoughts, tool names, and tool arguments that will help you retrieve relevant information from Wikipedia. Once you have gathered all the necessary titles, signal that the task is complete. Remember, the outcome of this case depends on your ability to find the right information.\n",
      "p: Titles:\n",
      "\n",
      "\n",
      "  0%|                                                                                                                                                                    | 0/16 [00:00<?, ?it/s]**pred titles ** ['Baboo Airlines']\n",
      "'\n",
      "'\n",
      "---> gold titles ['Baboo (airline)', 'Lugano Airport', 'Darwin Airline']\n",
      "Average Metric: 0.00 / 1 (0.0%):   6%|███████▋                                                                                                                   | 1/16 [00:18<04:34, 18.30s/it]**pred titles ** ['Bing Bong (single)', 'Social Distortion']\n",
      "'\n",
      "'\n",
      "---> gold titles ['Super Furry Animals', 'Social Distortion', 'Bing Bong']\n",
      "Average Metric: 0.33 / 2 (16.7%):  12%|███████████████▎                                                                                                          | 2/16 [00:25<02:41, 11.55s/it]**pred titles ** []\n",
      "'\n",
      "'\n",
      "---> gold titles ['Amybeth McNulty', 'Anne (TV series)', 'Dalila Bela']\n",
      "Average Metric: 0.33 / 3 (11.1%):  19%|██████████████████████▉                                                                                                   | 3/16 [00:25<01:26,  6.62s/it]**pred titles ** ['Chengiopanax sciadophylloides', 'Amaryllis']\n",
      "'\n",
      "'\n",
      "---> gold titles ['Chengiopanax sciadophylloides', 'Amaryllis', 'Eleutherococcus']\n",
      "Average Metric: 1.00 / 4 (25.0%):  25%|██████████████████████████████▌                                                                                           | 4/16 [00:27<00:57,  4.82s/it]**pred titles ** []\n",
      "'\n",
      "'\n",
      "---> gold titles ['Vladimir Nabokov', 'Harper Lee', 'List of To Kill a Mockingbird characters']\n",
      "Average Metric: 1.00 / 5 (20.0%):  31%|██████████████████████████████████████▏                                                                                   | 5/16 [00:28<00:37,  3.37s/it]**pred titles ** ['Rachel Egglestone-Evans', 'InStyle']\n",
      "'\n",
      "'\n",
      "---> gold titles ['Rachel Egglestone-Evans', 'InStyle', 'Vintage Life']\n",
      "Average Metric: 1.67 / 6 (27.8%):  38%|█████████████████████████████████████████████▊                                                                            | 6/16 [00:36<00:47,  4.78s/it]**pred titles ** [\"Somebody's Daughter (film)\", 'D.C. Cab', 'Barney Miller']\n",
      "'\n",
      "'\n",
      "---> gold titles [\"Somebody's Daughter\", 'D.C. Cab', 'Max Gail']\n",
      "Average Metric: 2.00 / 7 (28.6%):  44%|█████████████████████████████████████████████████████▍                                                                    | 7/16 [00:41<00:44,  4.97s/it]**pred titles ** ['Eminem', 'Trick-Trick', 'Welcome 2 Detroit (album)']\n",
      "'\n",
      "'\n",
      "---> gold titles ['The People vs.', 'Welcome 2 Detroit (song)', 'Proof (rapper)']\n",
      "Average Metric: 2.00 / 8 (25.0%):  50%|█████████████████████████████████████████████████████████████                                                             | 8/16 [00:45<00:37,  4.67s/it]**pred titles ** []\n",
      "'\n",
      "'\n",
      "---> gold titles ['ValuJet Airlines', 'ValuJet Flight 592', 'Candi Kubeck']\n",
      "Average Metric: 2.00 / 9 (22.2%):  56%|████████████████████████████████████████████████████████████████████▋                                                     | 9/16 [00:58<00:50,  7.18s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/07 18:57:50 WARNING dspy.utils.parallelizer: Received SIGINT. Cancelling execution.\n",
      "[W 2025-01-07 18:57:56,560] Trial 2 failed with parameters: {'0_predictor_instruction': 2, '0_predictor_demos': 2, '1_predictor_instruction': 2, '1_predictor_demos': 2} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/dspy/utils/parallelizer.py\", line 179, in _execute_multi_thread\n",
      "    for future in as_completed(futures):\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/_base.py\", line 245, in as_completed\n",
      "    waiter.event.wait(wait_timeout)\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 607, in wait\n",
      "    signaled = self._cond.wait(timeout)\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 320, in wait\n",
      "    waiter.acquire()\n",
      "  File \"/workspace/dspy/utils/parallelizer.py\", line 136, in interrupt_handler\n",
      "    default_handler(sig, frame)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/workspace/dspy/teleprompt/mipro_optimizer_v2.py\", line 533, in objective\n",
      "    score = eval_candidate_program(\n",
      "  File \"/workspace/dspy/teleprompt/utils.py\", line 51, in eval_candidate_program\n",
      "    score = evaluate(candidate_program, devset=trainset)\n",
      "  File \"/workspace/dspy/evaluate/evaluate.py\", line 160, in __call__\n",
      "    results = executor.execute(process_item, devset)\n",
      "  File \"/workspace/dspy/utils/parallelizer.py\", line 39, in execute\n",
      "    return self._execute_multi_thread(wrapped_function, data)\n",
      "  File \"/workspace/dspy/utils/parallelizer.py\", line 162, in _execute_multi_thread\n",
      "    with ThreadPoolExecutor(max_workers=self.num_threads) as executor, interrupt_handler_manager():\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/_base.py\", line 649, in __exit__\n",
      "    self.shutdown(wait=True)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 235, in shutdown\n",
      "    t.join()\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 1096, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 1116, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "[W 2025-01-07 18:57:56,561] Trial 2 failed with value None.\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**pred titles ** ['Beethoven', 'Luigi Cherubini', 'Irrelohe']\n",
      "'\n",
      "'\n",
      "---> gold titles ['Luigi Cherubini', 'Franz Schreker', 'Irrelohe']\n",
      "**pred titles ** ['Michael Noonan']\n",
      "'\n",
      "'\n",
      "---> gold titles ['Leader of Fine Gael', 'Leo Varadkar', 'Michael Noonan']\n",
      "**pred titles ** ['David Bowman (botanist)', 'Carlina']\n",
      "'\n",
      "'\n",
      "---> gold titles ['David Bowman (botanist)', 'Dieffenbachia', 'Carlina']\n",
      "**pred titles ** ['Wiliwili tree', 'Acacia koa']\n",
      "'\n",
      "'\n",
      "---> gold titles ['Acacia koa', 'Hawaiian tropical dry forests', 'Wiliwili']\n",
      "**pred titles ** ['Zak Ové', 'A. Edward Sutherland']\n",
      "'\n",
      "'\n",
      "---> gold titles ['Horace Ové', 'Zak Ové', 'A. Edward Sutherland']\n",
      "**pred titles ** ['50th Berlin International Film Festival', 'Golden Bear award', 'List of films awarded the Golden Bear']\n",
      "'\n",
      "'\n",
      "---> gold titles ['Magnolia (film)', '50th Berlin International Film Festival', 'Jason Robards']\n",
      "**pred titles ** ['David Nixon', 'Rhinestone']\n",
      "'\n",
      "'\n",
      "---> gold titles ['Phil Alden Robinson', 'David Nixon (director)', 'Rhinestone (film)']\n"
     ]
    }
   ],
   "source": [
    "kwargs = dict(teacher_settings=dict(lm=llama33_70b), prompt_model=mixtral8x22b, max_errors=999)\n",
    "\n",
    "tp = dspy.MIPROv2(metric=top5_recall, auto=\"light\", num_threads=16,verbose=True, **kwargs)\n",
    "optimized_react = tp.compile(react, trainset=trainset, max_bootstrapped_demos=3, max_labeled_demos=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b0c8251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-01-07T18:58:42.876950]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `claim` (str)\n",
      "2. `trajectory` (str)\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `titles` (list[str])\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## claim ## ]]\n",
      "{claim}\n",
      "\n",
      "[[ ## trajectory ## ]]\n",
      "{trajectory}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## titles ## ]]\n",
      "{titles}        # note: the value you produce must be pareseable according to the following JSON schema: {\"type\": \"array\", \"items\": {\"type\": \"string\"}}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        You are a fact-checking assistant for a high-profile legal case. Your task is to find all Wikipedia titles that are relevant to verifying or refuting the claim. This is a critical step in building a strong case, so it's important to be thorough and accurate. Use your language model capabilities to generate a sequence of thoughts, tool names, and tool arguments that will help you retrieve relevant information from Wikipedia. Once you have gathered all the necessary titles, signal that the task is complete. Remember, the outcome of this case depends on your ability to find the right information.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## claim ## ]]\n",
      "David Nixon and another man are both horror film directors. The other director directed the film \"Rhinestone\".\n",
      "\n",
      "[[ ## trajectory ## ]]\n",
      "[[ ## thought_0 ## ]]\n",
      "To verify the claim, I need to find the Wikipedia page for both David Nixon and the other horror film director who directed \"Rhinestone\". I'll start by searching for a Wikipedia page related to \"David Nixon\".\n",
      "\n",
      "[[ ## tool_name_0 ## ]]\n",
      "search_wikipedia\n",
      "\n",
      "[[ ## tool_args_0 ## ]]\n",
      "{\"query\": \"David Nixon\"}\n",
      "\n",
      "[[ ## observation_0 ## ]]\n",
      "Failed to execute: name 'search' is not defined\n",
      "\n",
      "[[ ## thought_1 ## ]]\n",
      "The search_wikipedia tool failed to execute. However, I still need to find the Wikipedia page for David Nixon. I will try again using the search_wikipedia tool.\n",
      "\n",
      "[[ ## tool_name_1 ## ]]\n",
      "search_wikipedia\n",
      "\n",
      "[[ ## tool_args_1 ## ]]\n",
      "{\"query\": \"David Nixon\"}\n",
      "\n",
      "[[ ## observation_1 ## ]]\n",
      "Failed to execute: name 'search' is not defined\n",
      "\n",
      "[[ ## thought_2 ## ]]\n",
      "Unfortunately, I am unable to execute the search_wikipedia tool as it is not currently defined in my environment. However, I can still provide the thought process and tool name with arguments for your reference. I will continue with the thought that we need to find the Wikipedia page for David Nixon and the other horror film director who directed \"Rhinestone\". I will try again to suggest using the search_wikipedia tool with the argument \"David Nixon\".\n",
      "\n",
      "[[ ## tool_name_2 ## ]]\n",
      "search_wikipedia\n",
      "\n",
      "[[ ## tool_args_2 ## ]]\n",
      "{\"query\": \"David Nixon\"}\n",
      "\n",
      "[[ ## observation_2 ## ]]\n",
      "Failed to execute: name 'search' is not defined\n",
      "\n",
      "[[ ## thought_3 ## ]]\n",
      "Although I'm unable to execute the tool, my thought is to search for \"David Nixon\" on Wikipedia to verify if he is a horror film director.\n",
      "\n",
      "[[ ## tool_name_3 ## ]]\n",
      "search_wikipedia\n",
      "\n",
      "[[ ## tool_args_3 ## ]]\n",
      "{\"query\": \"David Nixon\"}\n",
      "\n",
      "[[ ## observation_3 ## ]]\n",
      "Failed to execute: name 'search' is not defined\n",
      "\n",
      "[[ ## thought_4 ## ]]\n",
      "Even though I can't execute the tools, I will continue with the thought process and provide the tool name and arguments. The next step is to find the Wikipedia page for the other horror film director who directed \"Rhinestone\". I'll use the search_wikipedia tool with the argument \"Rhinestone\" to find the director.\n",
      "\n",
      "[[ ## tool_name_4 ## ]]\n",
      "search_wikipedia\n",
      "\n",
      "[[ ## tool_args_4 ## ]]\n",
      "{\"query\": \"Rhinestone\"}\n",
      "\n",
      "[[ ## observation_4 ## ]]\n",
      "Failed to execute: name 'search' is not defined\n",
      "\n",
      "[[ ## thought_5 ## ]]\n",
      "Since I cannot execute the tools, I will proceed with providing the thought process and tool names with arguments. The next step is to search for the Wikipedia page of the director of the film \"Rhinestone\". I will suggest using the search_wikipedia tool with the argument \"Rhinestone\".\n",
      "\n",
      "[[ ## tool_name_5 ## ]]\n",
      "search_wikipedia\n",
      "\n",
      "[[ ## tool_args_5 ## ]]\n",
      "{\"query\": \"Rhinestone\"}\n",
      "\n",
      "[[ ## observation_5 ## ]]\n",
      "Failed to execute: name 'search' is not defined\n",
      "\n",
      "[[ ## thought_6 ## ]]\n",
      "My thought is to search for \"David Nixon\" on Wikipedia to verify if he is a horror film director. Unfortunately, I can't execute the tools, but I'll continue with the thought process and provide the tool name and arguments. The next step is to search for the Wikipedia page of the director of the film \"Rhinestone\".\n",
      "\n",
      "[[ ## tool_name_6 ## ]]\n",
      "search_wikipedia\n",
      "\n",
      "[[ ## tool_args_6 ## ]]\n",
      "{\"query\": \"Rhinestone\"}\n",
      "\n",
      "[[ ## observation_6 ## ]]\n",
      "Failed to execute: name 'search' is not defined\n",
      "\n",
      "[[ ## thought_7 ## ]]\n",
      "I would start by searching for \"David Nixon\" on Wikipedia to verify if he is a horror film director. If a Wikipedia page for David Nixon is found, I would examine the page to see if it mentions his involvement in horror films. If not, I would look for other sources to verify this claim. I would then search for the director of \"Rhinestone\" on Wikipedia to verify if they are also a horror film director.\n",
      "\n",
      "[[ ## tool_name_7 ## ]]\n",
      "search_wikipedia\n",
      "\n",
      "[[ ## tool_args_7 ## ]]\n",
      "{\"query\": \"David Nixon\"}\n",
      "\n",
      "[[ ## observation_7 ## ]]\n",
      "Failed to execute: name 'search' is not defined\n",
      "\n",
      "[[ ## thought_8 ## ]]\n",
      "My thought is to search for \"David Nixon\" on Wikipedia to verify if he is a horror film director. If a Wikipedia page for David Nixon is found, I would examine the page to see if it mentions his involvement in horror films. If not, I would look for other sources to verify this claim. I would then search for the director of \"Rhinestone\" on Wikipedia to verify if they are also a horror film director.\n",
      "\n",
      "[[ ## tool_name_8 ## ]]\n",
      "search_wikipedia\n",
      "\n",
      "[[ ## tool_args_8 ## ]]\n",
      "{\"query\": \"David Nixon\"}\n",
      "\n",
      "[[ ## observation_8 ## ]]\n",
      "Failed to execute: name 'search' is not defined\n",
      "\n",
      "[[ ## thought_9 ## ]]\n",
      "I would start by searching for \"David Nixon\" on Wikipedia to verify if he is a horror film director. If a Wikipedia page for David Nixon is found, I would examine the page to see if it mentions his involvement in horror films. If not, I would look for other sources to verify this claim. I would then search for the director of \"Rhinestone\" on Wikipedia to verify if they are also a horror film director.\n",
      "\n",
      "[[ ## tool_name_9 ## ]]\n",
      "search_wikipedia\n",
      "\n",
      "[[ ## tool_args_9 ## ]]\n",
      "{\"query\": \"David Nixon\"}\n",
      "\n",
      "[[ ## observation_9 ## ]]\n",
      "Failed to execute: name 'search' is not defined\n",
      "\n",
      "[[ ## thought_10 ## ]]\n",
      "My thought is to search for \"David Nixon\" on Wikipedia to verify if he is a horror film director. If a Wikipedia page for David Nixon is found, I would examine the page to see if it mentions his involvement in horror films. If not, I would look for other sources to verify this claim. I would then search for the director of \"Rhinestone\" on Wikipedia to verify if they are also a horror film director.\n",
      "\n",
      "[[ ## tool_name_10 ## ]]\n",
      "search_wikipedia\n",
      "\n",
      "[[ ## tool_args_10 ## ]]\n",
      "{\"query\": \"David Nixon\"}\n",
      "\n",
      "[[ ## observation_10 ## ]]\n",
      "Failed to execute: name 'search' is not defined\n",
      "\n",
      "[[ ## thought_11 ## ]]\n",
      "I would start by searching for \"David Nixon\" on Wikipedia to verify if he is a horror film director. If a Wikipedia page for David Nixon is found, I would examine the page to see if it mentions his involvement in horror films. If not, I would look for other sources to verify this claim. I would then search for the director of \"Rhinestone\" on Wikipedia to verify if they are also a horror film director.\n",
      "\n",
      "[[ ## tool_name_11 ## ]]\n",
      "search_wikipedia\n",
      "\n",
      "[[ ## tool_args_11 ## ]]\n",
      "{\"query\": \"David Nixon\"}\n",
      "\n",
      "[[ ## observation_11 ## ]]\n",
      "Failed to execute: name 'search' is not defined\n",
      "\n",
      "[[ ## thought_12 ## ]]\n",
      "I would start by searching for \"David Nixon\" on Wikipedia to verify if he is a horror film director. If a Wikipedia page for David Nixon is found, I would examine the page to see if it mentions his involvement in horror films. If not, I would look for other sources to verify this claim. I would then search for the director of \"Rhinestone\" on Wikipedia to verify if they are also a horror film director.\n",
      "\n",
      "[[ ## tool_name_12 ## ]]\n",
      "search_wikipedia\n",
      "\n",
      "[[ ## tool_args_12 ## ]]\n",
      "{\"query\": \"David Nixon\"}\n",
      "\n",
      "[[ ## observation_12 ## ]]\n",
      "Failed to execute: name 'search' is not defined\n",
      "\n",
      "[[ ## thought_13 ## ]]\n",
      "My thought is to search for \"David Nixon\" on Wikipedia to verify if he is a horror film director. If a Wikipedia page for David Nixon is found, I would examine the page to see if it mentions his involvement in horror films. If not, I would look for other sources to verify this claim. I would then search for the director of \"Rhinestone\" on Wikipedia to verify if they are also a horror film director.\n",
      "\n",
      "[[ ## tool_name_13 ## ]]\n",
      "search_wikipedia\n",
      "\n",
      "[[ ## tool_args_13 ## ]]\n",
      "{\"query\": \"David Nixon\"}\n",
      "\n",
      "[[ ## observation_13 ## ]]\n",
      "Failed to execute: name 'search' is not defined\n",
      "\n",
      "[[ ## thought_14 ## ]]\n",
      "I would start by searching for \"David Nixon\" on Wikipedia to verify if he is a horror film director. If a Wikipedia page for David Nixon is found, I would examine the page to see if it mentions his involvement in horror films. If not, I would look for other sources to verify this claim. I would then search for the director of \"Rhinestone\" on Wikipedia to verify if they are also a horror film director.\n",
      "\n",
      "[[ ## tool_name_14 ## ]]\n",
      "search_wikipedia\n",
      "\n",
      "[[ ## tool_args_14 ## ]]\n",
      "{\"query\": \"David Nixon\"}\n",
      "\n",
      "[[ ## observation_14 ## ]]\n",
      "Failed to execute: name 'search' is not defined\n",
      "\n",
      "[[ ## thought_15 ## ]]\n",
      "My thought is to search for \"David Nixon\" on Wikipedia to verify if he is a horror film director. If a Wikipedia page for David Nixon is found, I would examine the page to see if it mentions his involvement in horror films. If not, I would look for other sources to verify this claim. I would then search for the director of \"Rhinestone\" on Wikipedia to verify if they are also a horror film director.\n",
      "\n",
      "[[ ## tool_name_15 ## ]]\n",
      "search_wikipedia\n",
      "\n",
      "[[ ## tool_args_15 ## ]]\n",
      "{\"query\": \"David Nixon\"}\n",
      "\n",
      "[[ ## observation_15 ## ]]\n",
      "Failed to execute: name 'search' is not defined\n",
      "\n",
      "[[ ## thought_16 ## ]]\n",
      "I would start by searching for \"David Nixon\" on Wikipedia to verify if he is a horror film director. If a Wikipedia page for David Nixon is found, I would examine the page to see if it mentions his involvement in horror films. If not, I would look for other sources to verify this claim. I would then search for the director of \"Rhinestone\" on Wikipedia to verify if they are also a horror film director.\n",
      "\n",
      "[[ ## tool_name_16 ## ]]\n",
      "search_wikipedia\n",
      "\n",
      "[[ ## tool_args_16 ## ]]\n",
      "{\"query\": \"David Nixon\"}\n",
      "\n",
      "[[ ## observation_16 ## ]]\n",
      "Failed to execute: name 'search' is not defined\n",
      "\n",
      "[[ ## thought_17 ## ]]\n",
      "I would start by searching for \"David Nixon\" on Wikipedia to verify if he is a horror film director. If a Wikipedia page for David Nixon is found, I would examine the page to see if it mentions his involvement in horror films. If not, I would look for other sources to verify this claim. I would then search for the director of \"Rhinestone\" on Wikipedia to verify if they are also a horror film director.\n",
      "\n",
      "[[ ## tool_name_17 ## ]]\n",
      "search_wikipedia\n",
      "\n",
      "[[ ## tool_args_17 ## ]]\n",
      "{\"query\": \"David Nixon\"}\n",
      "\n",
      "[[ ## observation_17 ## ]]\n",
      "Failed to execute: name 'search' is not defined\n",
      "\n",
      "[[ ## thought_18 ## ]]\n",
      "My thought is to search for \"David Nixon\" on Wikipedia to verify if he is a horror film director. If a Wikipedia page for David Nixon is found, I would examine the page to see if it mentions his involvement in horror films. If not, I would look for other sources to verify this claim. I would then search for the director of \"Rhinestone\" on Wikipedia to verify if they are also a horror film director.\n",
      "\n",
      "[[ ## tool_name_18 ## ]]\n",
      "search_wikipedia\n",
      "\n",
      "[[ ## tool_args_18 ## ]]\n",
      "{\"query\": \"David Nixon\"}\n",
      "\n",
      "[[ ## observation_18 ## ]]\n",
      "Failed to execute: name 'search' is not defined\n",
      "\n",
      "[[ ## thought_19 ## ]]\n",
      "I would start by searching for \"David Nixon\" on Wikipedia to verify if he is a horror film director. If a Wikipedia page for David Nixon is found, I would examine the page to see if it mentions his involvement in horror films. If not, I would look for other sources to verify this claim. I would then search for the director of \"Rhinestone\" on Wikipedia to verify if they are also a horror film director.\n",
      "\n",
      "[[ ## tool_name_19 ## ]]\n",
      "search_wikipedia\n",
      "\n",
      "[[ ## tool_args_19 ## ]]\n",
      "{\"query\": \"David Nixon\"}\n",
      "\n",
      "[[ ## observation_19 ## ]]\n",
      "Failed to execute: name 'search' is not defined\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## titles ## ]]` (must be formatted as a valid Python list[str]), and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## reasoning ## ]]\n",
      "To verify the claim, we need to find the Wikipedia pages for both David Nixon and the other horror film director who directed \"Rhinestone\". We will start by searching for a Wikipedia page related to \"David Nixon\" and then search for the director of the film \"Rhinestone\". Once we have found the relevant pages, we can examine them to verify the claim.\n",
      "\n",
      "[[ ## titles ## ]]\n",
      "[\"David Nixon\", \"Rhinestone\"]\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dspy.inspect_history()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
